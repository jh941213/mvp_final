#!/usr/bin/env python3
"""
ì±„íŒ… API ë¼ìš°í„° - ë°±ì—…
"""

import time
import uuid
import json
import os
from datetime import datetime
from typing import Dict, Any, List, AsyncGenerator
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from fastapi.responses import StreamingResponse, FileResponse

from app.models.chat_models import (
    ChatRequest,
    ChatResponse,
    ChatMessage,
    AgentInfo,
    MessageRole,
    AgentType,
    ChatStats,
    MultihopQuery,
    StormRequest,
    StormResponse,
    StormConfig,
    ModelConfig,
    get_available_models,
    get_default_model,
    get_model_by_name
)
from app.core.logging_config import get_logger, LogContext
from app.services.agent_service import AgentService

router = APIRouter()
logger = get_logger("chat")

@router.post("/chat", response_model=ChatResponse)
async def chat_with_agents(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    agent_service: AgentService = Depends()
):
    """
    ë©€í‹°ì—ì´ì „íŠ¸ì™€ ì±„íŒ… (STORM ëª¨ë“œ ì§€ì›)
    """
    start_time = time.time()
    request_id = str(uuid.uuid4())
    
    # ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    LogContext.set_request_context(request_id, "POST", "/chat")
    LogContext.set_user_context(request.user_id)
    
    try:
        logger.info("Chat request received", 
                   user_id=request.user_id, 
                   message_length=len(request.message),
                   session_id=request.session_id,
                   agent_mode=request.agent_mode)
        
        # ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if not agent_service:
            raise HTTPException(
                status_code=503, 
                detail="Agent service not available"
            )
        
        # ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        session_id = request.session_id
        if not session_id:
            session_id = str(uuid.uuid4())
            logger.info("New session created", session_id=session_id)
        
        LogContext.set_session_context(session_id)
        
        # ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— ë©”ì‹œì§€ ì „ë‹¬ (agent_mode ì§€ì›)
        try:
            # ConversationManagerë¡œ ì„¸ì…˜ ì—°ì†ì„± í™•ì¸
            session_exists = False
            conversation_count = 0
            
            if agent_service.conversation_manager:
                context = agent_service.conversation_manager.get_context_for_session(session_id)
                if context:
                    session_exists = True
                    history = await agent_service.get_conversation_history(session_id)
                    conversation_count = len(history)
                    logger.info("Continuing existing ConversationManager session", 
                               session_id=session_id,
                               message_count=conversation_count)
            
            # STORM ëª¨ë“œ ë˜ëŠ” ì¼ë°˜ ëª¨ë“œ ì²˜ë¦¬
            agent_response = await agent_service.process_message(
                message=request.message,
                user_id=request.user_id,
                session_id=session_id,
                context=request.context,
                agent_mode=request.agent_mode or "normal",
                model_name=request.model_name
            )
            
            processing_time = time.time() - start_time
            
            # ì„¸ì…˜ ë©”íƒ€ë°ì´í„° êµ¬ì„±
            session_metadata = agent_response.get("metadata", {})
            session_metadata.update({
                "session_exists": session_exists,
                "conversation_manager": bool(agent_service.conversation_manager),
                "session_continuity": True,
                "conversation_count": conversation_count,
                "multiturn_support": True,
                "agent_mode": request.agent_mode or "normal",
                "storm_enabled": request.agent_mode == "storm",
                "azure_sql_storage": session_metadata.get("azure_sql_storage", False),
                "processing_time": processing_time
            })
            
            # ì‘ë‹µ êµ¬ì„±
            response = ChatResponse(
                response=agent_response.get("response", "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                session_id=session_id,
                agent_info=AgentInfo(
                    name=agent_response.get("agent_name", "Enhanced_MagenticOne_Agent"),
                    type=_map_agent_type(agent_response.get("agent_type", "orchestrator")),
                    capabilities=agent_response.get("tools_used", []),
                    description=agent_response.get("agent_description", "Enhanced AI ì—ì´ì „íŠ¸"),
                    confidence=agent_response.get("confidence", 0.8),
                    tools_used=agent_response.get("tools_used", []),
                    execution_time=agent_response.get("execution_time", processing_time)
                ),
                conversation_history=await _get_conversation_history(agent_service, session_id),
                suggested_actions=agent_response.get("suggested_actions", []),
                metadata=session_metadata,
                processing_time=processing_time
            )
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í†µê³„ ì—…ë°ì´íŠ¸
            background_tasks.add_task(
                _update_chat_stats,
                agent_service,
                request.user_id,
                session_id,
                processing_time,
                True,
                request.agent_mode or "normal"
            )
            
            logger.info("Chat response generated successfully",
                       session_id=session_id,
                       processing_time=processing_time,
                       agent_type=response.agent_info.type,
                       agent_mode=request.agent_mode)
            
            return response
            
        except Exception as agent_error:
            logger.error("Agent processing failed", 
                        error=str(agent_error),
                        session_id=session_id,
                        agent_mode=request.agent_mode)
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤íŒ¨ í†µê³„ ì—…ë°ì´íŠ¸
            background_tasks.add_task(
                _update_chat_stats,
                agent_service,
                request.user_id,
                session_id,
                time.time() - start_time,
                False,
                request.agent_mode or "normal"
            )
            
            raise HTTPException(
                status_code=500,
                detail=f"ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(agent_error)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Unexpected error in chat endpoint", 
                    error=str(e),
                    request_id=request_id)
        raise HTTPException(
            status_code=500,
            detail="ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )
    finally:
        LogContext.clear_context()

@router.post("/stream")
async def chat_stream(request: ChatRequest, agent_service: AgentService = Depends()):
    """ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ - ì‹¤ì‹œê°„ ì‘ë‹µ"""
    try:
        logger.info("Streaming chat request received", 
                   extra={
                       "user_id": request.user_id,
                       "session_id": request.session_id,
                       "agent_mode": request.agent_mode,
                       "message_length": len(request.message)
                   })

        async def generate_response():
            try:
                logger.info("Processing message stream",
                           extra={
                               "user_id": request.user_id,
                               "session_id": request.session_id,
                               "agent_mode": request.agent_mode
                           })

                # STORM ëª¨ë“œì¸ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                if request.agent_mode == "storm":
                    storm_config = request.context.get("storm_config", {}) if request.context else {}
                    topic = storm_config.get("topic", request.message)
                    editor_count = storm_config.get("editor_count", 1)
                    human_in_the_loop = storm_config.get("human_in_the_loop", False)
                    
                    logger.info("Starting STORM research",
                               extra={
                                   "user_id": request.user_id,
                                   "session_id": request.session_id,
                                   "topic": topic
                               })

                    # ì§„í–‰ìƒí™© ìŠ¤íŠ¸ë¦¬ë°
                    storm_system = agent_service.storm_service.storm_system
                    
                    final_result = None
                    error_occurred = False
                    
                    try:
                        async for progress in storm_system.run_parallel_storm_research(
                            topic=topic,
                            enable_human_loop=human_in_the_loop,
                            editor_count=editor_count
                        ):
                            # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì „ì†¡
                            yield f"data: {json.dumps(progress, ensure_ascii=False)}\n\n"
                            
                            # ìµœì¢… ê²°ê³¼ ì €ì¥
                            if progress.get("type") == "storm_complete":
                                final_result = progress.get("content", "")
                                
                    except Exception as storm_error:
                        error_occurred = True
                        error_msg = f"STORM ì—°êµ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(storm_error)}"
                        logger.error(error_msg)
                        yield f"data: {json.dumps({'type': 'error', 'message': error_msg}, ensure_ascii=False)}\n\n"
                    
                    # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬ ë° íŒŒì¼ ì €ì¥
                    if final_result and not error_occurred:
                        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"storm_article_{timestamp}.md"
                        file_path = f"generated_articles/{filename}"
                        
                        # ë””ë ‰í† ë¦¬ ìƒì„±
                        import os
                        os.makedirs("generated_articles", exist_ok=True)
                        
                        # íŒŒì¼ ì €ì¥
                        try:
                            with open(file_path, 'w', encoding='utf-8') as f:
                                f.write(final_result)
                            
                            # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€ì™€ ë‹¤ìš´ë¡œë“œ ë§í¬ ì „ì†¡
                            completion_data = {
                                "type": "storm_final_complete",
                                "message": "ğŸ‰ STORM ì—°êµ¬ ì™„ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                                "content": final_result,
                                "file_path": file_path,
                                "filename": filename,
                                "download_url": f"/api/v1/download/{filename}",
                                "word_count": len(final_result.split()),
                                "char_count": len(final_result)
                            }
                            yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                            
                        except Exception as file_error:
                            yield f"data: {json.dumps({'type': 'error', 'message': f'íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(file_error)}'}, ensure_ascii=False)}\n\n"
                    
                    elif not error_occurred:
                        # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                        yield f"data: {json.dumps({'type': 'error', 'message': 'STORM ì—°êµ¬ê°€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"

                # ì¼ë°˜ ì±„íŒ… ëª¨ë“œ
                else:
                    response = await agent_service.process_message(
                        message=request.message,
                        session_id=request.session_id,
                        user_id=request.user_id,
                        agent_mode=request.agent_mode or "auto",
                        model_name=request.model_name,
                        context=request.context
                    )
                    
                    # ì¼ë°˜ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
                    for chunk in response.content.split('\n'):
                        if chunk.strip():
                            yield f"data: {json.dumps({'type': 'message', 'content': chunk}, ensure_ascii=False)}\n\n"
                    
                    yield f"data: {json.dumps({'type': 'complete'}, ensure_ascii=False)}\n\n"

            except Exception as e:
                error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                logger.error(error_msg)
                yield f"data: {json.dumps({'type': 'error', 'message': error_msg}, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            generate_response(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream"
            }
        )

    except Exception as e:
        logger.error(f"Streaming endpoint error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@router.get("/download/{filename}")
async def download_file(filename: str):
    """ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        file_path = f"generated_articles/{filename}"
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        from fastapi.responses import FileResponse
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='text/markdown'
        )
        
    except Exception as e:
        logger.error(f"File download error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# STORM ë‹¨ìˆœ ì—°êµ¬ API ì œê±°ë¨ - ëª¨ë“  ìš”ì²­ì€ /chat ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ ì²˜ë¦¬
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ agent_mode='storm'ê³¼ í•¨ê»˜ /chatìœ¼ë¡œ ìš”ì²­í•˜ë„ë¡ í†µí•©ë¨

@router.get("/chat/capabilities")
async def get_chat_capabilities(
    agent_service: AgentService = Depends()
):
    """
    ì±„íŒ… ì‹œìŠ¤í…œ ëŠ¥ë ¥ ì¡°íšŒ (STORM í¬í•¨)
    """
    try:
        capabilities = {
            "agents": [
                {
                    "type": "hr",
                    "name": "HR ì—ì´ì „íŠ¸",
                    "description": "ì¸ì‚¬ ì—…ë¬´ ì „ë¬¸ ì—ì´ì „íŠ¸",
                    "available": True
                },
                {
                    "type": "bulletin",
                    "name": "ê²Œì‹œíŒ ì—ì´ì „íŠ¸",
                    "description": "ê³µì§€ì‚¬í•­ ë° ê²Œì‹œíŒ ê´€ë¦¬",
                    "available": True
                },
                {
                    "type": "project",
                    "name": "í”„ë¡œì íŠ¸ ì—ì´ì „íŠ¸",
                    "description": "í”„ë¡œì íŠ¸ ê´€ë¦¬ ì „ë¬¸ ì—ì´ì „íŠ¸",
                    "available": True
                },
                {
                    "type": "ktds_info",
                    "name": "KTDS ì •ë³´ ì—ì´ì „íŠ¸",
                    "description": "íšŒì‚¬ ì •ë³´ ë° ì•ˆë‚´",
                    "available": True
                },
                {
                    "type": "storm",
                    "name": "STORM ì—°êµ¬ ì—ì´ì „íŠ¸",
                    "description": "ì‹¬ì¸µ ì—°êµ¬ ë° ìœ„í‚¤ ì‘ì„±",
                    "available": agent_service.storm_service is not None
                }
            ],
            "features": {
                "streaming": False,
                "session_management": True,
                "conversation_history": True,
                "multi_turn": True,
                "storm_research": agent_service.storm_service is not None,
                "model_selection": True
            }
        }
        
        return capabilities
        
    except Exception as e:
        logger.error("Failed to get chat capabilities", error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì±„íŒ… ì‹œìŠ¤í…œ ëŠ¥ë ¥ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

@router.get("/chat/models")
async def get_available_chat_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    """
    try:
        models = get_available_models()
        default_model = get_default_model()
        
        return {
            "models": [
                {
                    "name": model.name,
                    "display_name": model.display_name,
                    "description": model.description,
                    "provider": model.provider,
                    "context_window": model.context_window,
                    "max_tokens": model.max_tokens,
                    "capabilities": model.capabilities,
                    "is_default": model.is_default
                }
                for model in models.values()
            ],
            "default_model": default_model.name
        }
        
    except Exception as e:
        logger.error("Failed to get available models", error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

@router.get("/chat/history/{session_id}", response_model=List[ChatMessage])
async def get_chat_history(
    session_id: str,
    agent_service: AgentService = Depends()
):
    """
    ì„¸ì…˜ì˜ ì±„íŒ… ê¸°ë¡ ì¡°íšŒ
    """
    try:
        history = await _get_conversation_history(agent_service, session_id)
        return history
    except Exception as e:
        logger.error("Failed to get chat history", 
                    session_id=session_id, 
                    error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì±„íŒ… ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

@router.get("/chat/stats/{user_id}", response_model=ChatStats)
async def get_chat_stats(
    user_id: str,
    agent_service: AgentService = Depends()
):
    """
    ì‚¬ìš©ìì˜ ì±„íŒ… í†µê³„ ì¡°íšŒ
    """
    try:
        stats = await agent_service.get_user_chat_stats(user_id)
        
        return ChatStats(
            total_messages=stats.get("total_messages", 0),
            avg_response_time=stats.get("average_response_time", 0.0),
            active_sessions=stats.get("active_sessions", 0),
            agent_usage=stats.get("agent_usage", {})
        )
        
    except Exception as e:
        logger.error("Failed to get chat stats", 
                    user_id=user_id, 
                    error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì±„íŒ… í†µê³„ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

@router.post("/chat/analyze", response_model=MultihopQuery)
async def analyze_query_complexity(
    request: ChatRequest,
    agent_service: AgentService = Depends()
):
    """
    ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ (ë©€í‹°í™‰ ì¿¼ë¦¬ ê°ì§€)
    """
    try:
        analysis = await agent_service.analyze_query_complexity(request.message)
        
        return MultihopQuery(
            query=request.message,
            hops=analysis.get("sub_queries", []),
            context=analysis.get("context", {})
        )
        
    except Exception as e:
        logger.error("Failed to analyze query complexity", 
                    error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì¿¼ë¦¬ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

@router.delete("/chat/session/{session_id}")
async def clear_chat_session(
    session_id: str,
    agent_service: AgentService = Depends()
):
    """
    ì±„íŒ… ì„¸ì…˜ ì‚­ì œ
    """
    try:
        await agent_service.clear_session(session_id)
        return {"message": "ì„¸ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", "session_id": session_id}
    except Exception as e:
        logger.error("Failed to clear chat session", 
                    session_id=session_id, 
                    error=str(e))
        raise HTTPException(
            status_code=500,
            detail="ì„¸ì…˜ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

# Helper functions

def _map_agent_type(agent_type_str: str) -> AgentType:
    """ë¬¸ìì—´ì„ AgentType enumìœ¼ë¡œ ë§¤í•‘"""
    mapping = {
        "hr": AgentType.HR,
        "bulletin": AgentType.BULLETIN, 
        "project": AgentType.PROJECT,
        "ktds_info": AgentType.KTDS_INFO,
        "orchestrator": AgentType.ORCHESTRATOR,
        "storm": AgentType.STORM,
        "conversation_orchestrator": AgentType.ORCHESTRATOR,
        "fallback": AgentType.ORCHESTRATOR,
        "default": AgentType.ORCHESTRATOR
    }
    return mapping.get(agent_type_str.lower(), AgentType.ORCHESTRATOR)

async def _get_conversation_history(
    agent_service: AgentService, 
    session_id: str
) -> List[ChatMessage]:
    """ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    try:
        if hasattr(agent_service, 'get_conversation_history'):
            history = await agent_service.get_conversation_history(session_id)
            
            # íˆìŠ¤í† ë¦¬ë¥¼ ChatMessage ê°ì²´ë¡œ ë³€í™˜
            chat_messages = []
            for msg in history:
                try:
                    # ChatMessage ê°ì²´ì¸ì§€ í™•ì¸
                    if isinstance(msg, ChatMessage):
                        # ì´ë¯¸ ChatMessage ê°ì²´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        chat_messages.append(msg)
                        continue
                    
                    # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ (ConversationManagerì—ì„œ ë°˜í™˜ë˜ëŠ” í˜•íƒœ)
                    if isinstance(msg, dict):
                        # ConversationManagerì—ì„œ ë°˜í™˜ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° ì²˜ë¦¬
                        role = msg.get("role", "assistant")
                        content = msg.get("content", "")
                        timestamp = msg.get("timestamp", datetime.now().isoformat())
                        source = msg.get("source", None)
                        metadata = msg.get("metadata", {})
                        
                        # roleì´ MessageRole enumì¸ì§€ í™•ì¸
                        if isinstance(role, MessageRole):
                            role = role.value
                        
                        # timestampê°€ ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
                        if isinstance(timestamp, str):
                            try:
                                timestamp = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                            except:
                                timestamp = datetime.now()
                        
                        # ChatMessage ê°ì²´ ìƒì„±
                        chat_message = ChatMessage(
                            role=MessageRole(role),
                            content=content,
                            timestamp=timestamp,
                            metadata=metadata or {}
                        )
                        chat_messages.append(chat_message)
                    else:
                        # ë‹¤ë¥¸ ê°ì²´ì¸ ê²½ìš° (ì¼ë°˜ ê°ì²´)
                        role = getattr(msg, 'role', 'assistant')
                        if hasattr(role, 'value'):
                            role = role.value
                        content = getattr(msg, 'content', '')
                        timestamp = getattr(msg, 'timestamp', datetime.now())
                        metadata = getattr(msg, 'metadata', {})
                        
                        # ChatMessage ê°ì²´ ìƒì„±
                        chat_message = ChatMessage(
                            role=MessageRole(role),
                            content=content,
                            timestamp=timestamp,
                            metadata=metadata or {}
                        )
                        chat_messages.append(chat_message)
                    
                except Exception as msg_error:
                    logger.warning("Failed to process message in history", 
                                  session_id=session_id, 
                                  error=str(msg_error),
                                  message_type=type(msg).__name__)
                    continue
            
            return chat_messages
        else:
            return []
    except Exception as e:
        logger.warning("Failed to get conversation history", 
                      session_id=session_id, 
                      error=str(e))
        return []

async def _update_chat_stats(
    agent_service: AgentService,
    user_id: str,
    session_id: str,
    processing_time: float,
    success: bool,
    agent_mode: str = "normal"
):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì±„íŒ… í†µê³„ ì—…ë°ì´íŠ¸"""
    try:
        if hasattr(agent_service, 'update_chat_stats'):
            await agent_service.update_chat_stats(
                user_id=user_id,
                session_id=session_id,
                processing_time=processing_time,
                success=success
            )
        
        # STORM ëª¨ë“œ í†µê³„ ì¶”ê°€ ë¡œê¹…
        if agent_mode == "storm":
            logger.info("STORM usage recorded",
                       user_id=user_id,
                       session_id=session_id,
                       success=success,
                       processing_time=processing_time)
                       
    except Exception as e:
        logger.warning("Failed to update chat stats", 
                      user_id=user_id, 
                      agent_mode=agent_mode,
                      error=str(e))
