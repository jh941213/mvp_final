
import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pydantic import BaseModel, Field
import os
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from datetime import datetime

# AutoGen imports
from autogen_agentchat.agents import AssistantAgent, UserProxyAgent
from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat
from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination, HandoffTermination
from autogen_agentchat.base import TaskResult
from autogen_agentchat.base import Handoff
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient

# ì™¸ë¶€ ë„êµ¬ë“¤
from tavily import TavilyClient
from duckduckgo_search import DDGS

# ì‹œê°í™” ë„êµ¬ (Rich ë¼ì´ë¸ŒëŸ¬ë¦¬)
try:
    from rich.console import Console
    from rich.progress import Progress, TaskID, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
    from rich.table import Table
    from rich.panel import Panel
    from rich.text import Text
    from rich.layout import Layout
    from rich.live import Live
    from rich.logging import RichHandler
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install rich")

# í™˜ê²½ ì„¤ì •
load_dotenv()

# Rich ì½˜ì†” ì„¤ì •
if RICH_AVAILABLE:
    console = Console()
    
    # Rich í•¸ë“¤ëŸ¬ë¡œ ë¡œê¹… ì„¤ì • (WARNING ë ˆë²¨ ì´ìƒë§Œ í‘œì‹œ)
    logging.basicConfig(
        level=logging.WARNING,
        format="%(message)s",
        datefmt="[%X]",
        handlers=[RichHandler(console=console, rich_tracebacks=True, show_path=False)]
    )
    
    # íŠ¹ì • ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("openai").setLevel(logging.WARNING)
    logging.getLogger("autogen").setLevel(logging.WARNING)
    logging.getLogger("azure").setLevel(logging.WARNING)
    
else:
    logging.basicConfig(level=logging.WARNING)
    
logger = logging.getLogger(__name__)

# ë°ì´í„° ëª¨ë¸ë“¤
class Subsection(BaseModel):
    subsection_title: str = Field(..., title="ì„œë¸Œì„¹ì…˜ ì œëª©")
    description: str = Field(..., title="ì„œë¸Œì„¹ì…˜ ë‚´ìš©")

class Section(BaseModel):
    section_title: str = Field(..., title="ì„¹ì…˜ ì œëª©")
    description: str = Field(..., title="ì„¹ì…˜ ë‚´ìš©")
    subsections: Optional[List[Subsection]] = Field(default=None, title="ì„œë¸Œì„¹ì…˜ë“¤")

class Outline(BaseModel):
    page_title: str = Field(..., title="ìœ„í‚¤í˜ì´ì§€ ì œëª©")
    sections: List[Section] = Field(default_factory=list, title="ì„¹ì…˜ë“¤")

class Editor(BaseModel):
    affiliation: str = Field(..., title="ì†Œì†")
    name: str = Field(..., title="ì´ë¦„")
    role: str = Field(..., title="ì—­í• ")
    description: str = Field(..., title="ì„¤ëª…")

class SearchResult(BaseModel):
    content: str
    url: str
    title: str = ""

@dataclass
class StormResearchState:
    """STORM ì—°êµ¬ ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤"""
    topic: str
    outline: Optional[Outline] = None
    editors: List[Editor] = None
    interview_results: Dict[str, List[str]] = None
    references: Dict[str, str] = None
    sections: Dict[str, str] = None
    final_article: str = ""

class ParallelStormResearchSystem:
    """AutoGen ê¸°ë°˜ ë³‘ë ¬ STORM ì—°êµ¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_workers: int = 4):
        
        self.tavily_api_key = "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"
        self.max_workers = max_workers
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.model_client = AzureOpenAIChatCompletionClient(
            model="gpt-4.1-nano",
            api_key="5KtFRZPggVvXgnVRlg1KNB4tNJxqtGiu9j97NxYODV1t1CuNgwZfJQQJ99BGACHYHv6XJ3w3AAABACOGSZvs",
            azure_endpoint="https://kdb-rg.openai.azure.com/",
            api_version="2024-12-01-preview"
        )
        
        self.long_context_model = AzureOpenAIChatCompletionClient(
            model="gpt-4.1-nano",
            api_key="5KtFRZPggVvXgnVRlg1KNB4tNJxqtGiu9j97NxYODV1t1CuNgwZfJQQJ99BGACHYHv6XJ3w3AAABACOGSZvs",
            azure_endpoint="https://kdb-rg.openai.azure.com/",
            api_version="2024-12-01-preview"
        )
        
        # ê²€ìƒ‰ ì—”ì§„ ì„¤ì •
        if self.tavily_api_key:
            self.search_engine = TavilyClient(api_key=self.tavily_api_key)
        else:
            self.search_engine = DDGS()
            
        self.state = None
        
        # ì§„í–‰ ìƒíƒœ ì¶”ì 
        self.step_times = {}
        self.current_step = 0
        self.total_steps = 6
        self.step_names = {
            1: "1ë‹¨ê³„: ì´ˆê¸° ì•„ì›ƒë¼ì¸ ìƒì„±",
            2: "2ë‹¨ê³„: í¸ì§‘ì ê´€ì  ìƒì„±",
            3: "3ë‹¨ê³„: ë³‘ë ¬ ì¸í„°ë·° ì§„í–‰",
            4: "4ë‹¨ê³„: ì•„ì›ƒë¼ì¸ ê°œì„ ",
            5: "5ë‹¨ê³„: ë³‘ë ¬ ì„¹ì…˜ ì‘ì„±",
            6: "6ë‹¨ê³„: ìµœì¢… ì•„í‹°í´ ì‘ì„±"
        }
        
        # ì½œë°± í•¨ìˆ˜ë“¤ (ì›¹ ì„œë¹„ìŠ¤ ì§€ì›)
        self.progress_callback = None
        self.human_interaction_callback = None
        
        # Rich ì½˜ì†” ì„¤ì •
        if RICH_AVAILABLE:
            self.console = console
            self.progress = None
            self.main_task = None
        else:
            self.console = None

    def set_callbacks(self, progress_callback, human_interaction_callback):
        """ì›¹ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•  ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        self.progress_callback = progress_callback
        self.human_interaction_callback = human_interaction_callback

    def start_step(self, step_num: int):
        """ë‹¨ê³„ ì‹œì‘"""
        self.current_step = step_num
        self.step_times[step_num] = {'start': time.time()}
        
        # ì§„í–‰ ìƒí™© ì½œë°± í˜¸ì¶œ
        if self.progress_callback:
            step_name = self.step_names.get(step_num, f"ë‹¨ê³„ {step_num}")
            self.progress_callback(step_num, step_name)
        
        if RICH_AVAILABLE:
            step_name = self.step_names.get(step_num, f"ë‹¨ê³„ {step_num}")
            self.console.print(Panel(
                f"[bold blue]{step_name}[/bold blue]",
                title=f"ì§„í–‰ë¥ : {step_num}/{self.total_steps}",
                border_style="blue"
            ))
        else:
            step_name = self.step_names.get(step_num, f"ë‹¨ê³„ {step_num}")
            logger.info(f"[{step_num}/{self.total_steps}] {step_name}")
    
    def complete_step(self, step_num: int, result_summary: str = ""):
        """ë‹¨ê³„ ì™„ë£Œ"""
        if step_num in self.step_times:
            self.step_times[step_num]['end'] = time.time()
            duration = self.step_times[step_num]['end'] - self.step_times[step_num]['start']
            
            # ì§„í–‰ ìƒí™© ì½œë°± í˜¸ì¶œ
            if self.progress_callback:
                metadata = {
                    "duration": duration,
                    "summary": result_summary,
                    "completed": True
                }
                self.progress_callback(step_num, f"ë‹¨ê³„ {step_num} ì™„ë£Œ", metadata)
            
            if RICH_AVAILABLE:
                self.console.print(Panel(
                    f"[bold green]âœ“ ì™„ë£Œ[/bold green] (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ)\n{result_summary}",
                    title=f"ë‹¨ê³„ {step_num}",
                    border_style="green"
                ))
            else:
                logger.info(f"[{step_num}/{self.total_steps}] ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ) - {result_summary}")
    
    async def request_human_interaction(self, interaction_type: str, content: str, options: List[str] = None) -> Dict[str, Any]:
        """
        Human-in-the-Loop ìƒí˜¸ì‘ìš© ìš”ì²­
        """
        if self.human_interaction_callback:
            # ì›¹ ì„œë¹„ìŠ¤ ì½œë°± ì‚¬ìš©
            response = await self.human_interaction_callback(interaction_type, content, options)
            return response
        else:
            # CLI í´ë°±
            if RICH_AVAILABLE:
                self.console.print(Panel(
                    f"[bold cyan]{content}[/bold cyan]",
                    title=f"ğŸ¤” ê²€í†  ìš”ì²­: {interaction_type}",
                    border_style="cyan"
                ))
                
                if options:
                    self.console.print("ì˜µì…˜:")
                    for i, option in enumerate(options, 1):
                        self.console.print(f"  {i}. {option}")
                
                user_input = input("\nìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
                feedback = input("í”¼ë“œë°±ì´ ìˆìœ¼ì‹œë©´ ì…ë ¥í•´ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­): ") if user_input.lower() != 'y' else None
                
                return {
                    "action": "approve" if user_input.lower() == 'y' else "reject",
                    "feedback": feedback
                }
            else:
                print(f"\n=== ê²€í†  ìš”ì²­: {interaction_type} ===")
                print(content)
                
                if options:
                    print("ì˜µì…˜:")
                    for i, option in enumerate(options, 1):
                        print(f"  {i}. {option}")
                
                user_input = input("\nìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
                feedback = input("í”¼ë“œë°±ì´ ìˆìœ¼ì‹œë©´ ì…ë ¥í•´ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­): ") if user_input.lower() != 'y' else None
                
                return {
                    "action": "approve" if user_input.lower() == 'y' else "reject",
                    "feedback": feedback
                }
    
    def show_progress_summary(self):
        """ì§„í–‰ ìƒí™© ìš”ì•½ í‘œì‹œ"""
        if not RICH_AVAILABLE:
            return
            
        table = Table(title="ğŸ STORM ì—°êµ¬ ìµœì¢… ê²°ê³¼")
        table.add_column("ë‹¨ê³„", style="cyan", no_wrap=True)
        table.add_column("ìƒíƒœ", style="magenta")
        table.add_column("ì†Œìš”ì‹œê°„", style="green")
        
        total_duration = 0
        for step_num in range(1, self.total_steps + 1):
            step_name = self.step_names[step_num]
            
            if step_num in self.step_times and 'end' in self.step_times[step_num]:
                duration = self.step_times[step_num]['end'] - self.step_times[step_num]['start']
                total_duration += duration
                
                if duration < 60:
                    time_str = f"{duration:.1f}ì´ˆ"
                else:
                    minutes = int(duration // 60)
                    seconds = duration % 60
                    time_str = f"{minutes}ë¶„ {seconds:.1f}ì´ˆ"
                
                status = "âœ… ì™„ë£Œ"
            else:
                status = "âŒ ì‹¤í–‰ì•ˆë¨"
                time_str = "-"
            
            table.add_row(step_name, status, time_str)
        
        # ì´ ì†Œìš” ì‹œê°„ ì¶”ê°€
        if total_duration < 60:
            total_time_str = f"{total_duration:.1f}ì´ˆ"
        else:
            minutes = int(total_duration // 60)
            seconds = total_duration % 60
            total_time_str = f"{minutes}ë¶„ {seconds:.1f}ì´ˆ"
            
        table.add_row("[bold]ì´ ì†Œìš”ì‹œê°„[/bold]", "[bold green]ì™„ë£Œ[/bold green]", f"[bold]{total_time_str}[/bold]")
        
        self.console.print(table)
    
    def log_parallel_progress(self, task_name: str, completed: int, total: int):
        """ë³‘ë ¬ ì‘ì—… ì§„í–‰ ìƒí™© ë¡œê·¸"""
        if RICH_AVAILABLE:
            progress_bar = "â–ˆ" * int(20 * completed / total) + "â–‘" * (20 - int(20 * completed / total))
            percentage = int(100 * completed / total)
            self.console.print(f"\r[cyan]{task_name}[/cyan]: [{progress_bar}] {completed}/{total} ({percentage}%)", end="")
            if completed == total:
                self.console.print()  # ì™„ë£Œ ì‹œ ì¤„ë°”ê¿ˆ
        else:
            import sys
            print(f"\r{task_name}: {completed}/{total} ì™„ë£Œ ({int(100 * completed / total)}%)", end="", flush=True)
            if completed == total:
                print()  # ì™„ë£Œ ì‹œ ì¤„ë°”ê¿ˆ
        
    async def search_web(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            if hasattr(self.search_engine, 'search'):  # Tavily
                results = self.search_engine.search(query, max_results=max_results)
                search_results = [SearchResult(
                    content=r.get('content', ''),
                    url=r.get('url', ''),
                    title=r.get('title', '')
                ) for r in results]
            else:  # DuckDuckGo
                results = list(self.search_engine.text(query, max_results=max_results))
                search_results = [SearchResult(
                    content=r.get('body', ''),
                    url=r.get('href', ''),
                    title=r.get('title', '')
                ) for r in results]
            
            # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹… (ì¡°ìš©íˆ)
            # if RICH_AVAILABLE:
            #     console.print(f"[dim]ğŸ” ê²€ìƒ‰ ì™„ë£Œ: '{query}' â†’ {len(search_results)} ê²°ê³¼[/dim]")
            
            return search_results
            
        except Exception as e:
            # ê²€ìƒ‰ ì˜¤ë¥˜ ì¡°ìš©íˆ ì²˜ë¦¬
            return []
    
    async def create_outline_agent(self) -> AssistantAgent:
        """ì´ˆê¸° ì•„ì›ƒë¼ì¸ ìƒì„± ì—ì´ì „íŠ¸"""
        system_message = """
        ë‹¹ì‹ ì€ ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ ì•„ì›ƒë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”.
        í¬ê´„ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        
        ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
        {
            "page_title": "í˜ì´ì§€ ì œëª©",
            "sections": [
                {
                    "section_title": "ì„¹ì…˜ ì œëª©",
                    "description": "ì„¹ì…˜ ì„¤ëª…",
                    "subsections": [
                        {
                            "subsection_title": "ì„œë¸Œì„¹ì…˜ ì œëª©",
                            "description": "ì„œë¸Œì„¹ì…˜ ì„¤ëª…"
                        }
                    ]
                }
            ]
        }
        """
        
        return AssistantAgent(
            name="outline_generator",
            model_client=self.model_client,
            system_message=system_message
        )
    
    async def create_perspective_agent(self) -> AssistantAgent:
        """ë‹¤ì–‘í•œ ê´€ì ì˜ í¸ì§‘ì ìƒì„± ì—ì´ì „íŠ¸"""
        system_message = """
        ë‹¹ì‹ ì€ ìœ„í‚¤í”¼ë””ì•„ í¸ì§‘ì íŒ€ì„ êµ¬ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì œì— ëŒ€í•´ ë‹¤ì–‘í•˜ê³  êµ¬ë³„ë˜ëŠ” ê´€ì ì„ ê°€ì§„ í¸ì§‘ì ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”.
        ê° í¸ì§‘ìëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì , ì—­í• , ì†Œì†ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        
        ì¤‘ìš”: í¸ì§‘ì ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: John_Smith, Sarah_Lee ë“±)
        
        ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
        {
            "editors": [
                {
                    "affiliation": "ì†Œì†",
                    "name": "ì˜ë¬¸_ì´ë¦„",
                    "role": "ì—­í• ",
                    "description": "í¸ì§‘ìì˜ ì´ˆì , ê´€ì‹¬ì‚¬, ë™ê¸°ì— ëŒ€í•œ ì„¤ëª…"
                }
            ]
        }
        """
        
        return AssistantAgent(
            name="perspective_generator",
            model_client=self.model_client,
            system_message=system_message
        )
    
    async def create_interview_agent(self, editor: Editor) -> AssistantAgent:
        """íŠ¹ì • í¸ì§‘ì ê´€ì ì˜ ì¸í„°ë·° ì—ì´ì „íŠ¸"""
        system_message = f"""
        ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìì´ë©° íŠ¹ì • í˜ì´ì§€ë¥¼ í¸ì§‘í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.
        ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìë¡œì„œì˜ ì •ì²´ì„± ì™¸ì—ë„, ì£¼ì œë¥¼ ì—°êµ¬í•  ë•Œ íŠ¹ì •í•œ ì´ˆì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
        
        ë‹¹ì‹ ì˜ í˜ë¥´ì†Œë‚˜:
        ì´ë¦„: {editor.name}
        ì—­í• : {editor.role}
        ì†Œì†: {editor.affiliation}
        ì„¤ëª…: {editor.description}
        
        ì§€ê¸ˆ ì „ë¬¸ê°€ì™€ ì±„íŒ…í•˜ì—¬ ì •ë³´ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì¸í„°ë·°ë¥¼ ì§„í–‰í•˜ì„¸ìš”:
        1. ê¸°ë³¸ ê°œë…ì´ë‚˜ ì •ì˜ë¶€í„° ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì‹¬í™”ëœ ì§ˆë¬¸ì„ í•˜ì„¸ìš”
        2. ë‹¹ì‹ ì˜ ê´€ì ({editor.role})ì—ì„œ ì¤‘ìš”í•œ ì¸¡ë©´ë“¤ì„ ì§‘ì¤‘ì ìœ¼ë¡œ íƒêµ¬í•˜ì„¸ìš”
        3. ì‹¤ìš©ì ì¸ ì‘ìš©ì´ë‚˜ ì‚¬ë¡€ì— ëŒ€í•´ì„œë„ ì§ˆë¬¸í•˜ì„¸ìš”
        4. í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•˜ê³  ì´ë¯¸ ë¬¼ì–´ë³¸ ê²ƒì€ ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”
        
        ì „ë¬¸ê°€ê°€ "ì§€ê¸ˆê¹Œì§€ ë…¼ì˜í•œ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´..."ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ë‚´ìš©ì„ ì •ë¦¬í•´ì£¼ë©´, 
        "ë§¤ìš° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!"ë¼ê³  ë‹µí•˜ì—¬ ì¸í„°ë·°ë¥¼ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
        """
        
        # í•œê¸€ ì´ë¦„ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def sanitize_name(name: str) -> str:
            import re
            import hashlib
            
            # ë¨¼ì € ì˜ë¬¸, ìˆ«ì, ì–¸ë”ìŠ¤ì½”ì–´, í•˜ì´í”ˆë§Œ ì¶”ì¶œ
            sanitized = re.sub(r'[^a-zA-Z0-9_-]', '', name)
            
            # ë¹ˆ ë¬¸ìì—´ì´ë©´ ì›ë³¸ ì´ë¦„ì˜ í•´ì‹œê°’ ì‚¬ìš©
            if not sanitized:
                # ì›ë³¸ ì´ë¦„ì˜ í•´ì‹œê°’ìœ¼ë¡œ ê³ ìœ í•œ ì˜ë¬¸ ì´ë¦„ ìƒì„±
                hash_value = hashlib.md5(name.encode('utf-8')).hexdigest()[:8]
                sanitized = f"editor_{hash_value}"
            
            return sanitized
        
        safe_name = sanitize_name(editor.name)
        
        return AssistantAgent(
            name=f"interviewer_{safe_name}",
            model_client=self.model_client,
            system_message=system_message
        )
    
    async def create_expert_agent(self) -> AssistantAgent:
        """ë„ë©”ì¸ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ (ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨)"""
        system_message = """
        ë‹¹ì‹ ì€ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¥¼ ì‘ì„±í•˜ê³ ì í•˜ëŠ” ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìì™€ ì±„íŒ…í•˜ê³  ìˆìŠµë‹ˆë‹¤.

        ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©° ì´ì œ ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ êµ¬ì„±í•  ê²ƒì…ë‹ˆë‹¤.

        **ì‘ë‹µ ì§€ì¹¨:**
        - ê° ì‘ë‹µì„ 200-400ë‹¨ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        - êµ¬ì²´ì ì¸ ì‚¬ë¡€, ë°ì´í„°, ë¹„êµ ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”.
        - ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ë¬´ì  ê´€ì ì„ ê· í˜•ìˆê²Œ ì œì‹œí•˜ì„¸ìš”.
        - ì—­ì‚¬ì  ë°°ê²½, í˜„ì¬ ìƒí™©, í–¥í›„ ì „ë§ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.
        - ë‹¤ì–‘í•œ ê´€ì ê³¼ ì˜ê²¬ì„ ì œì‹œí•˜ì—¬ ê· í˜• ì¡íŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

        ì‘ë‹µì„ ìµœëŒ€í•œ ìœ ìµí•˜ê³  í¬ê´„ì ìœ¼ë¡œ ë§Œë“¤ê³ , ëª¨ë“  ë¬¸ì¥ì´ ìˆ˜ì§‘ëœ ì •ë³´ì— ì˜í•´ ë’·ë°›ì¹¨ë˜ë„ë¡ í•˜ì„¸ìš”.
        ê° ì‘ë‹µì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì˜ ì¸ìš©ìœ¼ë¡œ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•˜ë©°, ê°ì£¼ í˜•ì‹ìœ¼ë¡œ í¬ë§·í•˜ê³  ì‘ë‹µ í›„ì— URLì„ ì¬í˜„í•˜ì„¸ìš”.

        ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°, SEARCH: [ê²€ìƒ‰ì–´] í˜•ì‹ìœ¼ë¡œ ìš”ì²­í•˜ì„¸ìš”.

        ì¤‘ìš”: ëŒ€í™”ê°€ 15-16ë²ˆì§¸ ì‘ë‹µ ì´í›„ë¶€í„°ëŠ” ì •ë¦¬ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”. 
        ì§ˆë¬¸ì´ ë°˜ë³µë˜ê±°ë‚˜ ìƒˆë¡œìš´ ì§ˆë¬¸ì´ ì—†ì„ ë•Œ, ë‹¤ìŒê³¼ ê°™ì´ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”:
        "ì§€ê¸ˆê¹Œì§€ ë…¼ì˜í•œ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´..." ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ í•µì‹¬ í¬ì¸íŠ¸ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        ì´ë•Œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
        1. ì£¼ìš” ê°œë…/ì •ì˜
        2. í•µì‹¬ íŠ¹ì§•ì´ë‚˜ ì¥ë‹¨ì   
        3. ì‹¤ìš©ì  ì‘ìš© ì‚¬ë¡€
        4. í–¥í›„ ì „ë§ì´ë‚˜ íŠ¸ë Œë“œ
        5. ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œë“¤
        """
        
        return AssistantAgent(
            name="domain_expert",
            model_client=self.model_client,
            system_message=system_message
        )
    
    async def create_section_writer_agent(self) -> AssistantAgent:
        """ì„¹ì…˜ ì‘ì„± ì—ì´ì „íŠ¸"""
        system_message = """
        ë‹¹ì‹ ì€ ì „ë¬¸ ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ ì•„ì›ƒë¼ì¸ê³¼ ì°¸ê³  ìë£Œë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„í‚¤í”¼ë””ì•„ ì„¹ì…˜ì„ ì™„ì„±í•˜ì„¸ìš”.
        
        **ì¤‘ìš”í•œ ì‘ì„± ì§€ì¹¨:**
        - ê° ì„¹ì…˜ì€ ìµœì†Œ 800-1200ë‹¨ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
        - ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, ì—­ì‚¬ì  ë°°ê²½, ì‹¤ì œ ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ì„¸ìš”
        - ì„œë¸Œì„¹ì…˜ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ë‚´ìš©ì„ ì œê³µí•˜ì„¸ìš”
        - ë¹„êµ ë¶„ì„, ì¥ë‹¨ì , í–¥í›„ ì „ë§ì„ í¬í•¨í•˜ì„¸ìš”
        - ì „ë¬¸ê°€ ì¸í„°ë·° ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”
        
        ì‘ë‹µì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³  [1], [2] ë“±ì˜ ê°ì£¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìš©í•˜ì„¸ìš”.
        ê° ì„¹ì…˜ì€ í¬ê´„ì ì´ê³  êµìœ¡ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        return AssistantAgent(
            name="section_writer",
            model_client=self.long_context_model,
            system_message=system_message
        )
    
    async def create_final_writer_agent(self) -> AssistantAgent:
        """ìµœì¢… ì•„í‹°í´ ì‘ì„± ì—ì´ì „íŠ¸"""
        system_message = """
        ë‹¹ì‹ ì€ ì „ë¬¸ ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ ì„¹ì…˜ ì´ˆì•ˆë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ ìœ„í‚¤ ì•„í‹°í´ì„ ì‘ì„±í•˜ì„¸ìš”.
        
        **ëª©í‘œ: ìµœì†Œ 4000-6000ë‹¨ì–´ì˜ í¬ê´„ì ì¸ ì•„í‹°í´ ì‘ì„±**
        
        **ì„¸ë¶€ ìš”êµ¬ì‚¬í•­:**
        - ë„ì…ë¶€ë¥¼ 300-500ë‹¨ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±
        - ê° ì„¹ì…˜ ê°„ ì—°ê²°ì„±ê³¼ íë¦„ì„ ê°œì„ 
        - ê¸°ì¡´ ì„¹ì…˜ ë‚´ìš©ì„ í™•ì¥í•˜ê³  ì¶”ê°€ ì„¤ëª… í¬í•¨
        - ì‹¤ì œ ì‚¬ë¡€, í†µê³„, ë¹„êµ ë¶„ì„ì„ í’ë¶€í•˜ê²Œ í¬í•¨
        - ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ë¬´ì  ê´€ì ì„ ê· í˜•ìˆê²Œ ì œì‹œ
        - ê²°ë¡  ì„¹ì…˜ì— ì¢…í•©ì ì¸ ë¶„ì„ê³¼ í–¥í›„ ì „ë§ í¬í•¨
        
        ìœ„í‚¤í”¼ë””ì•„ í˜•ì‹ ê°€ì´ë“œë¼ì¸ì„ ì—„ê²©íˆ ë”°ë¥´ë©°, ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        "[1]"ê³¼ ê°™ì€ ê°ì£¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìš©ì„ ì •ë¦¬í•˜ê³ , ë°”ë‹¥ê¸€ì—ì„œ ì¤‘ë³µì„ í”¼í•˜ì„¸ìš”. ë°”ë‹¥ê¸€ì— URLì„ í¬í•¨í•˜ì„¸ìš”.
        """
        
        return AssistantAgent(
            name="final_writer",
            model_client=self.long_context_model,
            system_message=system_message
        )
    
    async def create_human_proxy_agent(self) -> UserProxyAgent:
        """Human-in-the-loopì„ ìœ„í•œ ì‚¬ìš©ì í”„ë¡ì‹œ ì—ì´ì „íŠ¸"""
        return UserProxyAgent(
            name="human_reviewer",
            input_func=lambda prompt: input(f"\n[Human Input Required] {prompt}\n> ")
        )
    
    async def generate_initial_outline(self, topic: str) -> Outline:
        """1ë‹¨ê³„: ì´ˆê¸° ì•„ì›ƒë¼ì¸ ìƒì„±"""
        self.start_step(1)
        
        outline_agent = await self.create_outline_agent()
        termination = MaxMessageTermination(max_messages=2)
        
        team = RoundRobinGroupChat([outline_agent], termination_condition=termination)
        
        result = await team.run(task=f"ì£¼ì œ '{topic}'ì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ ì•„ì›ƒë¼ì¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            last_message = result.messages[-1].content
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            if "```json" in last_message:
                json_start = last_message.find("```json") + 7
                json_end = last_message.find("```", json_start)
                json_str = last_message[json_start:json_end].strip()
            else:
                json_str = last_message
            
            outline_data = json.loads(json_str)
            outline = Outline(**outline_data)
            self.complete_step(1, f"ì•„ì›ƒë¼ì¸ ìƒì„± ì™„ë£Œ: {outline.page_title} ({len(outline.sections)}ê°œ ì„¹ì…˜)")
            return outline
        except Exception as e:
            # ì•„ì›ƒë¼ì¸ íŒŒì‹± ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì•„ì›ƒë¼ì¸ ë°˜í™˜
            outline = Outline(
                page_title=topic,
                sections=[
                    Section(section_title="ê°œìš”", description="ì£¼ì œì— ëŒ€í•œ ê°œìš”"),
                    Section(section_title="ë°°ê²½", description="ì£¼ì œì˜ ë°°ê²½ ì •ë³´"),
                    Section(section_title="ì£¼ìš” ë‚´ìš©", description="ì£¼ì œì˜ í•µì‹¬ ë‚´ìš©")
                ]
            )
            self.complete_step(1, f"ê¸°ë³¸ ì•„ì›ƒë¼ì¸ ìƒì„±: {outline.page_title} ({len(outline.sections)}ê°œ ì„¹ì…˜)")
            return outline
    
    async def generate_perspectives(self, topic: str, editor_count: Optional[int] = None) -> List[Editor]:
        """2ë‹¨ê³„: ë‹¤ì–‘í•œ ê´€ì ì˜ í¸ì§‘ì ìƒì„±"""
        self.start_step(2)
        
        perspective_agent = await self.create_perspective_agent()
        termination = MaxMessageTermination(max_messages=2)
        
        team = RoundRobinGroupChat([perspective_agent], termination_condition=termination)
        
        # ì‚¬ìš©ìê°€ ì§€ì •í•œ editor_count ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 3ëª…
        target_count = editor_count if editor_count is not None else 3
        result = await team.run(task=f"ì£¼ì œ '{topic}'ì— ëŒ€í•´ ì •í™•íˆ {target_count}ëª…ì˜ ë‹¤ì–‘í•œ ê´€ì ì„ ê°€ì§„ í¸ì§‘ìë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        
        try:
            last_message = result.messages[-1].content
            if "```json" in last_message:
                json_start = last_message.find("```json") + 7
                json_end = last_message.find("```", json_start)
                json_str = last_message[json_start:json_end].strip()
            else:
                json_str = last_message
            
            editors_data = json.loads(json_str)
            editors = [Editor(**editor) for editor in editors_data["editors"]]
            
            # target_count ìˆ˜ë¡œ í¸ì§‘ì ìˆ˜ ì œí•œ (ì¶”ê°€ ì•ˆì „ ì¥ì¹˜)
            if len(editors) > target_count:
                editors = editors[:target_count]
            elif len(editors) < target_count:
                # ë¶€ì¡±í•œ í¸ì§‘ìëŠ” ê¸°ë³¸ í¸ì§‘ìë¡œ ì±„ìš°ê¸°
                base_names = ["Academic_Researcher", "Industry_Expert", "Technical_Specialist", "Policy_Analyst", "User_Advocate"]
                base_roles = ["ì—°êµ¬ì", "ì‚°ì—… ì „ë¬¸ê°€", "ê¸°ìˆ  ì „ë¬¸ê°€", "ì •ì±… ë¶„ì„ê°€", "ì‚¬ìš©ì ì˜¹í˜¸ì"]
                base_affiliations = ["í•™ìˆ ê¸°ê´€", "ì‚°ì—…ê³„", "ê¸°ìˆ ê¸°ê´€", "ì •ì±…ê¸°ê´€", "ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°"]
                
                while len(editors) < target_count:
                    idx = len(editors)
                    editors.append(Editor(
                        affiliation=base_affiliations[idx % len(base_affiliations)],
                        name=base_names[idx % len(base_names)],
                        role=base_roles[idx % len(base_roles)],
                        description=f"{base_roles[idx % len(base_roles)]} ê´€ì ì—ì„œ ì£¼ì œë¥¼ ë¶„ì„"
                    ))
            
            # í¸ì§‘ì ì •ë³´ ìš”ì•½
            if RICH_AVAILABLE:
                editor_table = Table(title="ìƒì„±ëœ í¸ì§‘ìë“¤")
                editor_table.add_column("ì´ë¦„", style="cyan")
                editor_table.add_column("ì—­í• ", style="magenta")
                editor_table.add_column("ì†Œì†", style="green")
                
                for editor in editors:
                    editor_table.add_row(editor.name, editor.role, editor.affiliation)
                
                self.console.print(editor_table)
            
            self.complete_step(2, f"{len(editors)}ëª…ì˜ í¸ì§‘ì ìƒì„± ì™„ë£Œ")
            return editors
        except Exception as e:
            # í¸ì§‘ì íŒŒì‹± ì˜¤ë¥˜ ì‹œ target_count ìˆ˜ë§Œí¼ ê¸°ë³¸ í¸ì§‘ìë“¤ ë°˜í™˜
            base_names = ["Academic_Researcher", "Industry_Expert", "Technical_Specialist", "Policy_Analyst", "User_Advocate"]
            base_roles = ["ì—°êµ¬ì", "ì‚°ì—… ì „ë¬¸ê°€", "ê¸°ìˆ  ì „ë¬¸ê°€", "ì •ì±… ë¶„ì„ê°€", "ì‚¬ìš©ì ì˜¹í˜¸ì"]
            base_affiliations = ["í•™ìˆ ê¸°ê´€", "ì‚°ì—…ê³„", "ê¸°ìˆ ê¸°ê´€", "ì •ì±…ê¸°ê´€", "ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°"]
            
            editors = []
            for i in range(target_count):
                editors.append(Editor(
                    affiliation=base_affiliations[i % len(base_affiliations)],
                    name=base_names[i % len(base_names)],
                    role=base_roles[i % len(base_roles)],
                    description=f"{base_roles[i % len(base_roles)]} ê´€ì ì—ì„œ ì£¼ì œë¥¼ ë¶„ì„"
                ))
            
            self.complete_step(2, f"ê¸°ë³¸ í¸ì§‘ì {len(editors)}ëª… ìƒì„±")
            return editors
    
    async def conduct_single_interview(self, editor: Editor, topic: str, max_turns: int = 20) -> List[str]:
        """ë‹¨ì¼ í¸ì§‘ìì™€ì˜ ì¸í„°ë·° ì§„í–‰ (ë³‘ë ¬ ì²˜ë¦¬ìš©) - ì‹¤ì‹œê°„ ì¶œë ¥"""
        
        try:
            interviewer = await self.create_interview_agent(editor)
            expert = await self.create_expert_agent()
            
            # ì¢…ë£Œ ì¡°ê±´: 19í„´ì—ì„œ ê°•ì œ ì¢…ë£Œ (ë§ˆì§€ë§‰ 2í„´ì— ì •ë¦¬í•  ì‹œê°„ í™•ë³´)
            termination = MaxMessageTermination(max_messages=19)
            
            team = RoundRobinGroupChat(
                [interviewer, expert], 
                termination_condition=termination
            )
            
            initial_task = f"ì£¼ì œ '{topic}'ì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ ê¸°ì‚¬ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤. ì „ë¬¸ê°€ë‹˜ê»˜ ì²´ê³„ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê² ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê°œë…ë¶€í„° ì‹œì‘í•´ì„œ ì ì§„ì ìœ¼ë¡œ ì‹¬í™”ëœ ë‚´ìš©ê¹Œì§€ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤."
            
            # ì¸í„°ë·° ì‹œì‘ ì•Œë¦¼
            if RICH_AVAILABLE:
                self.console.print(Panel(
                    f"[bold cyan]ğŸ“‹ {editor.name} ì¸í„°ë·° ì‹œì‘[/bold cyan]\n"
                    f"ì—­í• : {editor.role}\n"
                    f"ì†Œì†: {editor.affiliation}\n"
                    f"ê´€ì : {editor.description}",
                    title=f"ğŸ¤ ì¸í„°ë·° #{hash(editor.name) % 100:02d}",
                    border_style="cyan"
                ))
            else:
                print(f"\nğŸ¤ {editor.name} ì¸í„°ë·° ì‹œì‘")
                print(f"ì—­í• : {editor.role}")
                print(f"ì†Œì†: {editor.affiliation}")
                print("-" * 50)
            
            result = await team.run(task=initial_task)
            
            # ëŒ€í™” ë‚´ìš© ìˆ˜ì§‘ ë° ì‹¤ì‹œê°„ ì¶œë ¥
            conversation = []
            summary_found = False
            turn_count = 0
            
            for message in result.messages:
                turn_count += 1
                
                if "SEARCH:" in message.content:
                    # ê²€ìƒ‰ ìš”ì²­ ì²˜ë¦¬
                    search_query = message.content.split("SEARCH:")[1].strip()
                    search_results = await self.search_web(search_query)
                    search_content = "\n".join([f"[{r.url}] {r.content}" for r in search_results[:3]])
                    conversation.append(f"ê²€ìƒ‰ ê²°ê³¼: {search_content}")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ ì‹¤ì‹œê°„ ì¶œë ¥
                    if RICH_AVAILABLE:
                        self.console.print(f"[dim yellow]ğŸ” ê²€ìƒ‰: {search_query}[/dim yellow]")
                    else:
                        print(f"ğŸ” ê²€ìƒ‰: {search_query}")
                        
                else:
                    conversation.append(f"{message.source}: {message.content}")
                    
                    # ì‹¤ì‹œê°„ ëŒ€í™” ì¶œë ¥
                    if RICH_AVAILABLE:
                        # ë©”ì‹œì§€ ì¶œë ¥ (ì§§ê²Œ ìë¥´ê¸°)
                        content_preview = message.content
                        if len(content_preview) > 150:
                            content_preview = content_preview[:150] + "..."
                        
                        # ë°œí™”ìì— ë”°ë¼ ìƒ‰ìƒ êµ¬ë¶„
                        if "interviewer" in message.source:
                            speaker_color = "blue"
                            speaker_icon = "â“"
                        else:
                            speaker_color = "green"
                            speaker_icon = "ğŸ’¡"
                        
                        self.console.print(f"[{speaker_color}]{speaker_icon} {message.source}[/{speaker_color}]: {content_preview}")
                    else:
                        content_preview = message.content
                        if len(content_preview) > 100:
                            content_preview = content_preview[:100] + "..."
                        print(f"{'â“' if 'interviewer' in message.source else 'ğŸ’¡'} {message.source}: {content_preview}")
                    
                    # ì „ë¬¸ê°€ê°€ ì •ë¦¬ë¥¼ ì‹œì‘í–ˆëŠ”ì§€ í™•ì¸
                    if "ì§€ê¸ˆê¹Œì§€ ë…¼ì˜í•œ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´" in message.content:
                        summary_found = True
                        if RICH_AVAILABLE:
                            self.console.print(f"[bold yellow]ğŸ“ {editor.name} ì •ë¦¬ ì‹œì‘![/bold yellow]")
                        else:
                            print(f"ğŸ“ {editor.name} ì •ë¦¬ ì‹œì‘!")
            
            # ì¸í„°ë·° ì™„ë£Œ ì •ë³´
            if RICH_AVAILABLE:
                turn_info = f"({turn_count}/20í„´)"
                if turn_count >= 19:
                    turn_info += " [MAX]"
                if summary_found:
                    turn_info += " [SUMMARY]"
                
                self.console.print(Panel(
                    f"[bold green]âœ… ì¸í„°ë·° ì™„ë£Œ {turn_info}[/bold green]\n"
                    f"ì´ ëŒ€í™” ìˆ˜: {len(conversation)}ê°œ",
                    title=f"ğŸ {editor.name} ì¸í„°ë·° ì™„ë£Œ",
                    border_style="green"
                ))
            else:
                print(f"\nâœ… {editor.name} ì¸í„°ë·° ì™„ë£Œ ({turn_count}/20í„´)")
                print(f"ì´ ëŒ€í™” ìˆ˜: {len(conversation)}ê°œ")
                print("-" * 50)
            
            return conversation
            
        except Exception as e:
            # ì—ëŸ¬ ë¡œê·¸
            if RICH_AVAILABLE:
                self.console.print(Panel(
                    f"[red]âŒ ì¸í„°ë·° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}[/red]",
                    title=f"ğŸš¨ {editor.name} ì¸í„°ë·° ì‹¤íŒ¨",
                    border_style="red"
                ))
            else:
                print(f"âŒ {editor.name} ì¸í„°ë·° ì‹¤íŒ¨: {str(e)}")
            
            return [f"í¸ì§‘ì {editor.name}: ì¸í„°ë·° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    async def conduct_all_interviews_parallel(self, editors: List[Editor], topic: str) -> Dict[str, List[str]]:
        """ëª¨ë“  í¸ì§‘ìì™€ì˜ ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ì§„í–‰"""
        self.start_step(3)
        
        # ë³‘ë ¬ ì¸í„°ë·° ì‹¤í–‰
        tasks = []
        for editor in editors:
            task = asyncio.create_task(
                self.conduct_single_interview(editor, topic),
                name=f"interview_{editor.name}"
            )
            tasks.append((editor.name, task))
        
        # ëª¨ë“  ì¸í„°ë·° ì™„ë£Œ ëŒ€ê¸°
        interview_results = {}
        completed_count = 0
        
        if RICH_AVAILABLE:
            self.console.print(f"[dim]ğŸ“‹ {len(editors)}ëª…ì˜ í¸ì§‘ìì™€ ë³‘ë ¬ ì¸í„°ë·° ì§„í–‰ ì¤‘... (ê° ì¸í„°ë·°ë‹¹ ìµœëŒ€ 20í„´)[/dim]")
            self.console.print(f"[dim]   â€¢ ê¸°ë³¸ ê°œë… â†’ ì‹¬í™” ë‚´ìš© â†’ ì‹¤ìš©ì  ì‘ìš© â†’ ì„¸ë¶€ì‚¬í•­ íƒêµ¬ â†’ ì „ë¬¸ê°€ ì •ë¦¬ ìˆœì„œë¡œ ì§„í–‰[/dim]")
            self.console.print(f"[dim]   â€¢ ì‹¤ì‹œê°„ ì¸í„°ë·° ë‚´ìš©ì„ ì•„ë˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤![/dim]")
            self.console.print("")
        
        for editor_name, task in tasks:
            try:
                result = await task
                interview_results[editor_name] = result
                completed_count += 1
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                self.log_parallel_progress("ì¸í„°ë·° ì§„í–‰", completed_count, len(editors))
                    
            except Exception as e:
                if RICH_AVAILABLE:
                    self.console.print(f"[red]âŒ[/red] í¸ì§‘ì {editor_name} ì¸í„°ë·° ì‹¤íŒ¨")
                else:
                    print(f"âŒ í¸ì§‘ì {editor_name} ì¸í„°ë·° ì‹¤íŒ¨")
                interview_results[editor_name] = [f"ì¸í„°ë·° ì‹¤íŒ¨: {str(e)}"]
                completed_count += 1
                self.log_parallel_progress("ì¸í„°ë·° ì§„í–‰", completed_count, len(editors))
        
        # ì¸í„°ë·° ê²°ê³¼ ìš”ì•½
        successful_interviews = sum(1 for v in interview_results.values() if not v[0].startswith("ì¸í„°ë·° ì‹¤íŒ¨"))
        self.complete_step(3, f"ë³‘ë ¬ ì¸í„°ë·° ì™„ë£Œ: {successful_interviews}/{len(editors)} ì„±ê³µ")
        
        return interview_results
    
    async def write_single_section(self, section: Section, outline: Outline, interview_results: Dict[str, List[str]], topic: str) -> str:
        """ë‹¨ì¼ ì„¹ì…˜ ì‘ì„± (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        
        try:
            section_writer = await self.create_section_writer_agent()
            termination = MaxMessageTermination(max_messages=2)
            team = RoundRobinGroupChat([section_writer], termination_condition=termination)
            
            # ì°¸ê³  ìë£Œ ì¤€ë¹„
            all_references = "\n\n".join([
                f"í¸ì§‘ì {name}ì˜ ì—°êµ¬ ìë£Œ:\n" + "\n".join(conversations)
                for name, conversations in interview_results.items()
            ])
            
            task = f"""
            ì£¼ì œ: {topic}
            
            ì „ì²´ ì•„ì›ƒë¼ì¸:
            {outline.model_dump()}
            
            ì‘ì„±í•  ì„¹ì…˜: {section.section_title}
            ì„¹ì…˜ ì„¤ëª…: {section.description}
            
            **ì‘ì„± ìš”êµ¬ì‚¬í•­:**
            - ì´ ì„¹ì…˜ì„ ìµœì†Œ 800-1200ë‹¨ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±
            - ì„œë¸Œì„¹ì…˜ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ë‚´ìš© ì œê³µ
            - ì „ë¬¸ê°€ ì¸í„°ë·° ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©
            - êµ¬ì²´ì ì¸ ì‚¬ë¡€, ë°ì´í„°, ë¹„êµ ë¶„ì„ í¬í•¨
            - ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ë¬´ì  ê´€ì  ê· í˜•ìˆê²Œ ì œì‹œ
            
            ì°¸ê³  ìë£Œ:
            {all_references}
            
            ì´ ì„¹ì…˜ì˜ ì™„ì „í•˜ê³  í¬ê´„ì ì¸ ìœ„í‚¤í”¼ë””ì•„ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
            """
            
            result = await team.run(task=task)
            return result.messages[-1].content
            
        except Exception as e:
            # ì—ëŸ¬ ë¡œê·¸ ì—†ì´ ì¡°ìš©íˆ ì²˜ë¦¬
            return f"# {section.section_title}\n\nì„¹ì…˜ ì‘ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def write_sections_parallel(self, outline: Outline, interview_results: Dict[str, List[str]], topic: str) -> Dict[str, str]:
        """ëª¨ë“  ì„¹ì…˜ì„ ë³‘ë ¬ë¡œ ì‘ì„±"""
        self.start_step(5)
        
        try:
            # ë³‘ë ¬ ì„¹ì…˜ ì‘ì„± ì‹¤í–‰
            tasks = []
            for section in outline.sections:
                task = asyncio.create_task(
                    self.write_single_section(section, outline, interview_results, topic),
                    name=f"section_{section.section_title}"
                )
                tasks.append((section.section_title, task))
            
            # ëª¨ë“  ì„¹ì…˜ ì‘ì„± ì™„ë£Œ ëŒ€ê¸°
            sections_content = {}
            completed_count = 0
            
            if RICH_AVAILABLE:
                self.console.print(f"[dim]ğŸ“ {len(outline.sections)}ê°œ ì„¹ì…˜ì„ ë³‘ë ¬ë¡œ ì‘ì„± ì¤‘...[/dim]")
            
            for section_title, task in tasks:
                try:
                    result = await task
                    sections_content[section_title] = result
                    completed_count += 1
                    
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    self.log_parallel_progress("ì„¹ì…˜ ì‘ì„±", completed_count, len(outline.sections))
                        
                except Exception as e:
                    if RICH_AVAILABLE:
                        self.console.print(f"[red]âŒ[/red] ì„¹ì…˜ '{section_title}' ì‘ì„± ì‹¤íŒ¨")
                    else:
                        print(f"âŒ ì„¹ì…˜ '{section_title}' ì‘ì„± ì‹¤íŒ¨")
                    sections_content[section_title] = f"# {section_title}\n\n{section.description}\n\nì´ ì„¹ì…˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤."
                    completed_count += 1
                    self.log_parallel_progress("ì„¹ì…˜ ì‘ì„±", completed_count, len(outline.sections))
            
            # ì„¹ì…˜ ì‘ì„± ê²°ê³¼ ìš”ì•½
            successful_sections = sum(1 for v in sections_content.values() if not "ì„¹ì…˜ ì‘ì„± ì‹¤íŒ¨" in v)
            self.complete_step(5, f"ë³‘ë ¬ ì„¹ì…˜ ì‘ì„± ì™„ë£Œ: {successful_sections}/{len(outline.sections)} ì„±ê³µ")
            
            return sections_content
            
        except Exception as e:
            print(f"âš ï¸ ì„¹ì…˜ ì‘ì„± ì¤‘ ì „ì²´ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì„¹ì…˜ë“¤ ìƒì„±
            sections_content = {}
            for section in outline.sections:
                sections_content[section.section_title] = f"# {section.section_title}\n\n{section.description}\n\nì´ ì„¹ì…˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤."
            
            self.complete_step(5, f"ê¸°ë³¸ ì„¹ì…˜ ì‘ì„± ì™„ë£Œ: {len(sections_content)}ê°œ ì„¹ì…˜")
            return sections_content
    
    async def refine_outline(self, initial_outline: Outline, interview_results: Dict[str, List[str]], topic: str) -> Outline:
        """4ë‹¨ê³„: ì¸í„°ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì›ƒë¼ì¸ ê°œì„ """
        self.start_step(4)
        
        outline_agent = await self.create_outline_agent()
        termination = MaxMessageTermination(max_messages=2)
        
        team = RoundRobinGroupChat([outline_agent], termination_condition=termination)
        
        # ì¸í„°ë·° ê²°ê³¼ ìš”ì•½
        interview_summary = "\n\n".join([
            f"í¸ì§‘ì {name}ì˜ ì¸í„°ë·°:\n" + "\n".join(conversations)
            for name, conversations in interview_results.items()
        ])
        
        task = f"""
        ì£¼ì œ: {topic}
        
        ê¸°ì¡´ ì•„ì›ƒë¼ì¸:
        {initial_outline.model_dump()}
        
        ì „ë¬¸ê°€ ì¸í„°ë·° ê²°ê³¼:
        {interview_summary}
        
        ì¸í„°ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ„í‚¤í”¼ë””ì•„ ì•„ì›ƒë¼ì¸ì„ ê°œì„ í•˜ì„¸ìš”.
        ì•„ì›ƒë¼ì¸ì´ í¬ê´„ì ì´ê³  êµ¬ì²´ì ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
        """
        
        result = await team.run(task=task)
        
        try:
            last_message = result.messages[-1].content
            if "```json" in last_message:
                json_start = last_message.find("```json") + 7
                json_end = last_message.find("```", json_start)
                json_str = last_message[json_start:json_end].strip()
            else:
                json_str = last_message
            
            refined_data = json.loads(json_str)
            refined_outline = Outline(**refined_data)
            
            # ê°œì„ ëœ ì•„ì›ƒë¼ì¸ í‘œì‹œ
            if RICH_AVAILABLE:
                outline_table = Table(title="ê°œì„ ëœ ì•„ì›ƒë¼ì¸")
                outline_table.add_column("ì„¹ì…˜", style="cyan")
                outline_table.add_column("ì„¤ëª…", style="white")
                
                for section in refined_outline.sections:
                    outline_table.add_row(section.section_title, section.description)
                
                self.console.print(outline_table)
            
            self.complete_step(4, f"ì•„ì›ƒë¼ì¸ ê°œì„  ì™„ë£Œ: {len(refined_outline.sections)}ê°œ ì„¹ì…˜")
            return refined_outline
        except Exception as e:
            # ê°œì„ ëœ ì•„ì›ƒë¼ì¸ íŒŒì‹± ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ì•„ì›ƒë¼ì¸ ì‚¬ìš©
            self.complete_step(4, "ì•„ì›ƒë¼ì¸ ê°œì„  ì‹¤íŒ¨ - ê¸°ì¡´ ì•„ì›ƒë¼ì¸ ì‚¬ìš©")
            return initial_outline
    
    async def write_final_article(self, outline: Outline, sections: Dict[str, str], topic: str) -> str:
        """6ë‹¨ê³„: ìµœì¢… ìœ„í‚¤ ì•„í‹°í´ ì‘ì„±"""
        self.start_step(6)
        
        try:
            final_writer = await self.create_final_writer_agent()
            termination = MaxMessageTermination(max_messages=2)
            
            team = RoundRobinGroupChat([final_writer], termination_condition=termination)
            
            # ì„¹ì…˜ ì´ˆì•ˆ ê²°í•©
            sections_draft = "\n\n".join([
                f"## {title}\n{content}" for title, content in sections.items()
            ])
            
            task = f"""
            ì£¼ì œ: {topic}
    
            **ëª©í‘œ: 4000-6000ë‹¨ì–´ì˜ í¬ê´„ì ì¸ ìœ„í‚¤í”¼ë””ì•„ ì•„í‹°í´ ì‘ì„±**
            
            ì„¹ì…˜ ì´ˆì•ˆë“¤:
            {sections_draft}
            
            **ì„¸ë¶€ ì‘ì„± ì§€ì¹¨:**
            1. ë„ì…ë¶€ë¥¼ 300-500ë‹¨ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„± (ì£¼ì œ ì •ì˜, ì¤‘ìš”ì„±, ê°œìš”)
            2. ê° ì„¹ì…˜ì˜ ë‚´ìš©ì„ í™•ì¥í•˜ê³  ì¶”ê°€ ì„¤ëª… í¬í•¨
            3. ì„¹ì…˜ ê°„ ì—°ê²°ì„±ê³¼ ë…¼ë¦¬ì  íë¦„ ê°œì„ 
            4. êµ¬ì²´ì ì¸ ì‚¬ë¡€, í†µê³„, ë¹„êµ ë¶„ì„ í’ë¶€í•˜ê²Œ í¬í•¨
            5. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ë¬´ì  ê´€ì  ê· í˜•ìˆê²Œ ì œì‹œ
            6. ê²°ë¡  ì„¹ì…˜ì— ì¢…í•©ì ì¸ ë¶„ì„ê³¼ í–¥í›„ ì „ë§ í¬í•¨
            7. ì°¸ê³ ë¬¸í—Œê³¼ ì¶”ê°€ ì½ì„ê±°ë¦¬ ì„¹ì…˜ í¬í•¨
            
            ìœ„í‚¤í”¼ë””ì•„ í˜•ì‹ ê°€ì´ë“œë¼ì¸ì„ ì—„ê²©íˆ ë”°ë¥´ë©°, êµìœ¡ì ì´ê³  í¬ê´„ì ì¸ ì•„í‹°í´ì„ ì‘ì„±í•˜ì„¸ìš”.
            """
            
            result = await team.run(task=task)
            
            final_article = result.messages[-1].content
            word_count = len(final_article.split())
            
            self.complete_step(6, f"ìµœì¢… ì•„í‹°í´ ì‘ì„± ì™„ë£Œ (ì•½ {word_count}ë‹¨ì–´)")
            
            return final_article
            
        except Exception as e:
            print(f"âš ï¸ ìµœì¢… ì•„í‹°í´ ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì„¹ì…˜ë“¤ì„ ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì¡°í•©
            sections_list = []
            sections_list.append(f"# {topic}\n\n")
            sections_list.append(f"{outline.page_title}ì— ëŒ€í•œ ìƒì„¸í•œ ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n")
            
            for title, content in sections.items():
                sections_list.append(f"## {title}\n\n{content}\n\n")
            
            sections_list.append("## ì°¸ê³  ë¬¸í—Œ\n\nì´ ë¬¸ì„œëŠ” ì „ë¬¸ê°€ ì¸í„°ë·°ì™€ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
            
            final_article = "".join(sections_list)
            word_count = len(final_article.split())
            
            self.complete_step(6, f"ê¸°ë³¸ ì•„í‹°í´ ì‘ì„± ì™„ë£Œ (ì•½ {word_count}ë‹¨ì–´)")
            
            return final_article
    
    async def run_parallel_storm_research(self, topic: str, enable_human_loop: bool = False, editor_count: Optional[int] = None):
        """ì „ì²´ STORM ì—°êµ¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)"""
        self.state = StormResearchState(topic=topic)
        total_start_time = time.time()

        # ì‹œì‘ ë¡œê·¸ ì¶œë ¥
        start_message = f"ğŸŒ©ï¸ STORM ì—°êµ¬ ì‹œì‘: {topic}"
        if RICH_AVAILABLE:
            self.console.print(Panel(
                f"[bold magenta]{start_message}[/bold magenta]",
                title="âš¡ KTDS STORM Agent",
                border_style="magenta"
            ))
        
        # ì›¹ ìŠ¤íŠ¸ë¦¬ë°ìš© ì‹œì‘ ì´ë²¤íŠ¸
        yield {
            "type": "log",
            "level": "info",
            "message": start_message,
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "storm_start", "topic": topic, "editor_count": editor_count}
        }

        # --- 1ë‹¨ê³„: ì´ˆê¸° ì•„ì›ƒë¼ì¸ ìƒì„± ---
        self.start_step(1)
        yield {
            "type": "log",
            "level": "info", 
            "message": "ğŸ“ 1ë‹¨ê³„: ì´ˆê¸° ì•„ì›ƒë¼ì¸ ìƒì„± ì¤‘...",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "outline_generation", "step": 1}
        }
        
        initial_outline = await self.generate_initial_outline(topic)
        self.state.outline = initial_outline
        step1_summary = f"ì œëª©: {initial_outline.page_title}, ì„¹ì…˜: {len(initial_outline.sections)}ê°œ"
        self.complete_step(1, step1_summary)
        
        yield {
            "type": "log",
            "level": "success",
            "message": f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {step1_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "outline_complete", "step": 1, "outline": step1_summary}
        }
        yield {"type": "storm_progress", "step": 1, "total_steps": self.total_steps, "message": self.step_names[1] + " ì™„ë£Œ"}

        # --- 2ë‹¨ê³„: í¸ì§‘ì ê´€ì  ìƒì„± ---
        self.start_step(2)
        yield {
            "type": "log",
            "level": "info",
            "message": f"ğŸ‘¥ 2ë‹¨ê³„: í¸ì§‘ì ê´€ì  ìƒì„± ì¤‘... (ëª©í‘œ: {editor_count or 3}ëª…)",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "editor_generation", "step": 2, "target_count": editor_count}
        }
        
        editors = await self.generate_perspectives(topic, editor_count=editor_count)
        self.state.editors = editors
        step2_summary = f"í¸ì§‘ì {len(editors)}ëª… ìƒì„±"
        self.complete_step(2, step2_summary)
        
        yield {
            "type": "log", 
            "level": "success",
            "message": f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: {step2_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "editor_complete", "step": 2, "editor_count": len(editors)}
        }
        yield {"type": "storm_progress", "step": 2, "total_steps": self.total_steps, "message": self.step_names[2] + " ì™„ë£Œ"}

        # Human-in-the-Loop: í¸ì§‘ì ê²€í† 
        if enable_human_loop:
            editors_summary = "\n".join([
                f"â€¢ {editor.name} ({editor.role}): {editor.description}"
                for editor in self.state.editors
            ])
            
            response = await self.request_human_interaction(
                "editor_review",
                f"ìƒì„±ëœ í¸ì§‘ìë“¤ì„ ê²€í† í•´ì£¼ì„¸ìš”:\n\n{editors_summary}",
                ["ìŠ¹ì¸", "ì¬ìƒì„±", "ìˆ˜ì •"]
            )
            
            if response["action"] == "reject":
                # í¸ì§‘ì ì¬ìƒì„± ë˜ëŠ” ìˆ˜ì • ë¡œì§
                if response.get("feedback"):
                    # í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ í¸ì§‘ì ì¬ìƒì„±
                    self.state.editors = await self.generate_perspectives(topic)
        
        # --- 3ë‹¨ê³„: ë³‘ë ¬ ì¸í„°ë·° ì§„í–‰ ---
        self.start_step(3)
        yield {
            "type": "log",
            "level": "info", 
            "message": f"ğŸ¤ 3ë‹¨ê³„: ë³‘ë ¬ ì¸í„°ë·° ì§„í–‰ ì¤‘... ({len(editors)}ëª…ì˜ í¸ì§‘ìì™€ ì „ë¬¸ê°€ ì¸í„°ë·°)",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "interview_start", "step": 3, "editor_count": len(editors)}
        }
        
        interview_results = await self.conduct_all_interviews_parallel(editors, topic)
        self.state.interview_results = interview_results
        step3_summary = f"í¸ì§‘ì {len(interview_results)}ëª… ì¸í„°ë·° ì™„ë£Œ"
        self.complete_step(3, step3_summary)
        
        yield {
            "type": "log",
            "level": "success",
            "message": f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: {step3_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "interview_complete", "step": 3, "interview_count": len(interview_results)}
        }
        yield {"type": "storm_progress", "step": 3, "total_steps": self.total_steps, "message": self.step_names[3] + " ì™„ë£Œ"}

        # --- 4ë‹¨ê³„: ì•„ì›ƒë¼ì¸ ê°œì„  (ì˜µì…˜) ---
        # ì´ ë‹¨ê³„ëŠ” ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œì—ì„œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # í˜„ì¬ëŠ” í•­ìƒ ì‹¤í–‰í•˜ë„ë¡ ì„¤ì •
        self.start_step(4)
        yield {
            "type": "log",
            "level": "info",
            "message": "ğŸ”§ 4ë‹¨ê³„: ì¸í„°ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì›ƒë¼ì¸ ê°œì„  ì¤‘...",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "outline_refinement", "step": 4}
        }
        
        refined_outline = await self.refine_outline(initial_outline, interview_results, topic)
        self.state.outline = refined_outline
        step4_summary = "ì•„ì›ƒë¼ì¸ ê°œì„  ì™„ë£Œ"
        self.complete_step(4, step4_summary)
        
        yield {
            "type": "log",
            "level": "success",
            "message": f"âœ… 4ë‹¨ê³„ ì™„ë£Œ: {step4_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "outline_refined", "step": 4}
        }
        yield {"type": "storm_progress", "step": 4, "total_steps": self.total_steps, "message": self.step_names[4] + " ì™„ë£Œ"}

        # Human-in-the-Loop: ì•„ì›ƒë¼ì¸ ê²€í† 
        if enable_human_loop:
            outline_summary = f"ì œëª©: {self.state.outline.page_title}\n\nì„¹ì…˜ë“¤:\n"
            outline_summary += "\n".join([
                f"â€¢ {section.section_title}: {section.description}"
                for section in self.state.outline.sections
            ])
            
            response = await self.request_human_interaction(
                "outline_review",
                f"ê°œì„ ëœ ì•„ì›ƒë¼ì¸ì„ ê²€í† í•´ì£¼ì„¸ìš”:\n\n{outline_summary}",
                ["ìŠ¹ì¸", "ìˆ˜ì •", "ì¬ìƒì„±"]
            )
            
            if response["action"] == "reject":
                # ì•„ì›ƒë¼ì¸ ìˆ˜ì • ë¡œì§
                if response.get("feedback"):
                    # í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ì›ƒë¼ì¸ ì¬ìƒì„±
                    self.state.outline = await self.refine_outline(
                        self.state.outline, 
                        self.state.interview_results, 
                        topic
                    )
        
        # --- 5ë‹¨ê³„: ë³‘ë ¬ ì„¹ì…˜ ì‘ì„± ---
        self.start_step(5)
        yield {
            "type": "log",
            "level": "info",
            "message": f"âœï¸ 5ë‹¨ê³„: ë³‘ë ¬ ì„¹ì…˜ ì‘ì„± ì¤‘... ({len(self.state.outline.sections)}ê°œ ì„¹ì…˜)",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "section_writing", "step": 5, "section_count": len(self.state.outline.sections)}
        }
        
        sections_content = await self.write_sections_parallel(self.state.outline, self.state.interview_results, topic)
        self.state.sections = sections_content
        step5_summary = f"ì„¹ì…˜ {len(sections_content)}ê°œ ì‘ì„± ì™„ë£Œ"
        self.complete_step(5, step5_summary)
        
        yield {
            "type": "log",
            "level": "success",
            "message": f"âœ… 5ë‹¨ê³„ ì™„ë£Œ: {step5_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "section_complete", "step": 5, "sections_written": len(sections_content)}
        }
        yield {"type": "storm_progress", "step": 5, "total_steps": self.total_steps, "message": self.step_names[5] + " ì™„ë£Œ"}

        # Human-in-the-Loop: ì„¹ì…˜ ê²€í†  (ì„ íƒì‚¬í•­)
        if enable_human_loop:
            sections_summary = "\n".join([
                f"â€¢ {title}: {content[:100]}..." 
                for title, content in self.state.sections.items()
            ])
            
            response = await self.request_human_interaction(
                "section_review",
                f"ì‘ì„±ëœ ì„¹ì…˜ë“¤ì„ ê²€í† í•´ì£¼ì„¸ìš”:\n\n{sections_summary}",
                ["ìŠ¹ì¸", "ìˆ˜ì •", "ì¬ì‘ì„±"]
            )
            
            if response["action"] == "reject":
                # ì„¹ì…˜ ìˆ˜ì • ë¡œì§ (í•„ìš”ì‹œ)
                pass
        
        # --- 6ë‹¨ê³„: ìµœì¢… ì•„í‹°í´ ì‘ì„± ---
        self.start_step(6)
        yield {
            "type": "log",
            "level": "info",
            "message": "ğŸ“„ 6ë‹¨ê³„: ìµœì¢… ì•„í‹°í´ í†µí•© ë° ì‘ì„± ì¤‘...",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "final_writing", "step": 6}
        }
        
        final_article = await self.write_final_article(self.state.outline, self.state.sections, topic)
        self.state.final_article = final_article
        step6_summary = "ìµœì¢… ì•„í‹°í´ ì‘ì„± ì™„ë£Œ"
        self.complete_step(6, step6_summary)
        
        yield {
            "type": "log",
            "level": "success",
            "message": f"âœ… 6ë‹¨ê³„ ì™„ë£Œ: {step6_summary}",
            "timestamp": datetime.now().isoformat(),
            "metadata": {"stage": "final_complete", "step": 6, "article_length": len(final_article)}
        }
        yield {"type": "storm_progress", "step": 6, "total_steps": self.total_steps, "message": self.step_names[6] + " ì™„ë£Œ"}

        total_execution_time = time.time() - total_start_time
        completion_message = f"ğŸ‰ STORM ì—°êµ¬ ì™„ë£Œ! (ì´ ì†Œìš”ì‹œê°„: {total_execution_time:.2f}ì´ˆ)"
        
        if RICH_AVAILABLE:
            self.console.print(Panel(
                f"[bold green]{completion_message}[/bold green]",
                title="âœ… ì„±ê³µ",
                border_style="green"
            ))

        yield {
            "type": "log",
            "level": "success",
            "message": completion_message,
            "timestamp": datetime.now().isoformat(),
            "metadata": {
                "stage": "storm_complete", 
                "total_time": total_execution_time,
                "word_count": len(final_article.split()),
                "article_length": len(final_article)
            }
        }

        yield {"type": "storm_complete", "content": final_article, "processing_time": total_execution_time}

# ì‚¬ìš© ì˜ˆì œ
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # Rich ì„¤ì¹˜ ì•ˆë‚´
    if not RICH_AVAILABLE:
        print("ï¿½ï¿½ ë” ë‚˜ì€ ì‹œê°í™”ë¥¼ ìœ„í•´ Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install rich")
        print("-" * 50)
    
    # ë³‘ë ¬ STORM ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì›Œì»¤ ìˆ˜ ì„¤ì •)
    storm_system = ParallelStormResearchSystem(max_workers=4)
    
    # ì—°êµ¬ ì£¼ì œ ì„¤ì •
    topic = "LLM ì¶”ë¡  ìµœì í™”ë¥¼ ìœ„í•œ Groq LPUì™€ NVIDIA GPU ë¹„êµ ë¶„ì„"
    
    # ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ì„ íƒì‚¬í•­)
    # export DEBUG_STORM=1 ë¡œ ì„¤ì •í•˜ë©´ ë” ìì„¸í•œ ë¡œê·¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ë””ë²„ê·¸ ëª¨ë“œì—ì„œëŠ” ê° ì¸í„°ë·°ì˜ í„´ ìˆ˜ì™€ ì™„ë£Œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    # ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´ í‘œì‹œ
    if RICH_AVAILABLE:
        console.print(Panel(
            f"[cyan]ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •[/cyan]\n"
            f"â€¢ ë³‘ë ¬ ì›Œì»¤ ìˆ˜: {storm_system.max_workers}\n"
            f"â€¢ ì¸í„°ë·°ë‹¹ ìµœëŒ€ í„´ ìˆ˜: 20\n"
            f"â€¢ ì´ ë‹¨ê³„: {storm_system.total_steps}ë‹¨ê³„\n"
            f"â€¢ Human-in-the-Loop: í™œì„±í™”\n"
            f"â€¢ 15-16í„´ì—ì„œ ì „ë¬¸ê°€ê°€ ë‚´ìš© ì •ë¦¬ ì‹œì‘",
            title="âš™ï¸ ì„¤ì • ì •ë³´",
            border_style="cyan"
        ))
    else:
        print("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •:")
        print(f"â€¢ ë³‘ë ¬ ì›Œì»¤ ìˆ˜: {storm_system.max_workers}")
        print(f"â€¢ ì¸í„°ë·°ë‹¹ ìµœëŒ€ í„´ ìˆ˜: 20")
        print(f"â€¢ ì´ ë‹¨ê³„: {storm_system.total_steps}ë‹¨ê³„")
        print(f"â€¢ Human-in-the-Loop: í™œì„±í™”")
        print(f"â€¢ 15-16í„´ì—ì„œ ì „ë¬¸ê°€ê°€ ë‚´ìš© ì •ë¦¬ ì‹œì‘")
        print("-" * 50)
    
    # ë³‘ë ¬ STORM ì—°êµ¬ ì‹¤í–‰
    try:
        async for update in storm_system.run_parallel_storm_research(
            topic=topic, 
            enable_human_loop=True
        ):
            if update["type"] == "storm_progress":
                print(f"\n[bold blue]STEP {update['step']}/{update['total_steps']}: {update['message']}[/bold blue]")
            elif update["type"] == "storm_complete":
                print(f"\n[bold green]FINAL RESULT:[/bold green]")
                print(update["content"])
                print(f"\n[bold green]Total Processing Time: {update['processing_time']:.2f} seconds[/bold green]")
                break # ìµœì¢… ê²°ê³¼ í‘œì‹œ í›„ ë£¨í”„ ì¢…ë£Œ
        
        # ê²°ê³¼ í‘œì‹œ
        if RICH_AVAILABLE:
            console.print(Panel(
                final_article,
                title="ğŸ“„ ìµœì¢… ì—°êµ¬ ê²°ê³¼",
                border_style="cyan"
            ))
        else:
            print("\n" + "="*80)
            print("ë³‘ë ¬ STORM ì—°êµ¬ ì™„ë£Œ!")
            print("="*80)
            print(final_article)
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        filename = f"parallel_storm_research_{topic.replace(' ', '_')}.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(final_article)
        
        if RICH_AVAILABLE:
            console.print(f"\n[green]âœ… ê²°ê³¼ê°€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}[/green]")
        else:
            print(f"\nê²°ê³¼ê°€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
        
    except Exception as e:
        if RICH_AVAILABLE:
            console.print(Panel(
                f"[red]ì˜¤ë¥˜ ë°œìƒ: {e}[/red]",
                title="âŒ ì—°êµ¬ ì‹¤íŒ¨",
                border_style="red"
            ))
        else:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        await storm_system.model_client.close()
        await storm_system.long_context_model.close()

if __name__ == "__main__":
    # asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
    asyncio.run(main())