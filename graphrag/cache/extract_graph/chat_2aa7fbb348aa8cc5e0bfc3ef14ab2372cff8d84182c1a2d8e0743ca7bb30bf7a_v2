{"result": {"id": "chatcmpl-BpSi9hxrQQ4jSXDoiOKsyHNL4VrIy", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "(\"entity\"<|>MEMORY<|>COMPONENT<|>A protocol in AgentChat that allows for the storage and retrieval of useful facts, which can be added to the agent's context before specific steps)\n##\n(\"entity\"<|>ADD<|>TOOL<|>The `add` method is used to add new entries to the memory store, such as user preferences or other data)\n##\n(\"entity\"<|>QUERY<|>TOOL<|>The `query` method is used to retrieve relevant information from the memory store based on specific criteria or similarity scores)\n##\n(\"entity\"<|>UPDATE_CONTEXT<|>TOOL<|>The `update_context` method is used to modify or update the agent's internal `model_context` by adding retrieved information)\n##\n(\"entity\"<|>CLEAR<|>TOOL<|>The `clear` method is used to remove all entries from the memory store)\n##\n(\"entity\"<|>CLOSE<|>TOOL<|>The `close` method is used to clean up any resources used by the memory store)\n##\n(\"entity\"<|>LISTMEMORY<|>MEMORY_STORE<|>A simple list-based memory implementation that maintains memories in chronological order and appends the most recent memories to the agent's context)\n##\n(\"entity\"<|>MEMORYCONTENT<|>COMPONENT<|>A component representing the content to be stored in memory, including attributes like content, MIME type, and metadata)\n##\n(\"entity\"<|>MEMORYMIMETYPE<|>COMPONENT<|>A component specifying the MIME type of the memory content, such as TEXT)\n##\n(\"entity\"<|>ASSISTANTAGENT<|>AGENT<|>An agent created to assist with tasks, leveraging memory stores, tools, and model clients for enhanced functionality)\n##\n(\"entity\"<|>OPENAICHATCOMPLETIONCLIENT<|>MODEL_CLIENT<|>A model client for interacting with OpenAI's GPT-4 model, used for generating responses or performing tasks)\n##\n(\"entity\"<|>GET_WEATHER<|>TOOL<|>A tool function that retrieves weather information for a given city and unit system, such as metric or imperial)\n##\n(\"entity\"<|>CHROMADBVECTORMEMORY<|>MEMORY_STORE<|>A memory store that uses a vector database to store and retrieve information, part of the `autogen_ext` extensions package)\n##\n(\"entity\"<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>CONFIGURATION<|>A configuration class for persistent storage of ChromaDBVectorMemory, including parameters like collection name, persistence path, and similarity thresholds)\n##\n(\"entity\"<|>SENTENCETRANSFORMEREMBEDDINGFUNCTIONCONFIG<|>CONFIGURATION<|>A configuration class for the SentenceTransformer embedding function used by the ChromaDBVectorMemory store, specifying the model and its parameters)\n##\n(\"entity\"<|>TEMPFILE<|>COMPONENT<|>A component used to create temporary directories for storing persistent memory data during runtime)\n##\n(\"relationship\"<|>MEMORY<|>ADD<|>The `add` method is part of the Memory protocol and is used to add new entries to the memory store<|>8)\n##\n(\"relationship\"<|>MEMORY<|>QUERY<|>The `query` method is part of the Memory protocol and is used to retrieve relevant information from the memory store<|>8)\n##\n(\"relationship\"<|>MEMORY<|>UPDATE_CONTEXT<|>The `update_context` method is part of the Memory protocol and is used to modify the agent's context with retrieved information<|>8)\n##\n(\"relationship\"<|>MEMORY<|>CLEAR<|>The `clear` method is part of the Memory protocol and is used to remove all entries from the memory store<|>7)\n##\n(\"relationship\"<|>MEMORY<|>CLOSE<|>The `close` method is part of the Memory protocol and is used to clean up resources used by the memory store<|>7)\n##\n(\"relationship\"<|>LISTMEMORY<|>MEMORY<|>ListMemory is an implementation of the Memory protocol that maintains memories in chronological order<|>9)\n##\n(\"relationship\"<|>LISTMEMORY<|>MEMORYCONTENT<|>ListMemory stores MemoryContent, which includes user preferences and other data<|>8)\n##\n(\"relationship\"<|>MEMORYCONTENT<|>MEMORYMIMETYPE<|>MemoryContent specifies its MIME type using MemoryMimeType, such as TEXT<|>7)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>LISTMEMORY<|>The AssistantAgent uses ListMemory to manage and retrieve memory for providing consistent context in responses<|>9)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>OPENAICHATCOMPLETIONCLIENT<|>The AssistantAgent uses the OpenAIChatCompletionClient for generating responses and performing tasks<|>9)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>GET_WEATHER<|>The AssistantAgent uses the `get_weather` tool to retrieve weather information based on user queries<|>8)\n##\n(\"relationship\"<|>CHROMADBVECTORMEMORY<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>The ChromaDBVectorMemory store is configured for persistence using PersistentChromaDBVectorMemoryConfig<|>9)\n##\n(\"relationship\"<|>CHROMADBVECTORMEMORY<|>SENTENCETRANSFORMEREMBEDDINGFUNCTIONCONFIG<|>The ChromaDBVectorMemory store uses the SentenceTransformerEmbeddingFunctionConfig for embedding functions<|>8)\n##\n(\"relationship\"<|>TEMPFILE<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>Tempfile is used to create a temporary directory for the persistence path in PersistentChromaDBVectorMemoryConfig<|>6)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>CHROMADBVECTORMEMORY<|>The AssistantAgent can use ChromaDBVectorMemory to manage and retrieve memory for more complex use cases<|>9)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>MEMORY<|>The AssistantAgent uses the Memory protocol to manage and retrieve relevant information for tasks<|>9)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>UPDATE_CONTEXT<|>The AssistantAgent uses the `update_context` method to modify its internal context with retrieved memory<|>8)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>ADD<|>The AssistantAgent uses the `add` method to add user preferences and other data to its memory<|>8)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>QUERY<|>The AssistantAgent uses the `query` method to retrieve relevant information from its memory<|>8)\n<|COMPLETE|>", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "protected_material_code": {"filtered": false, "detected": false}, "protected_material_text": {"filtered": false, "detected": false}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1751604793, "model": "gpt-4o-2024-11-20", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_ee1d74bde0", "usage": {"completion_tokens": 1491, "prompt_tokens": 3943, "total_tokens": 5434, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 2560}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "jailbreak": {"filtered": false, "detected": false}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}, "input": {"messages": [{"content": "\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [agent, memory_store, embedding_function, configuration, component, tool, message, event, termination_condition, subscription, task, model_client, reasoning_model, context, workflow]\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: an integer score between 1 to 10, indicating strength of the relationship between the source entity and target entity\nFormat each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. If you have to translate into English, just translate the descriptions, nothing else!\n\n5. When finished, output <|COMPLETE|>.\n\n-Examples-\n######################\n\nExample 1:\n\nentity_types: [agent, memory_store, embedding_function, configuration, component, tool, message, event, termination_condition, subscription, task, model_client, reasoning_model, context, workflow]\ntext:\n, you will need to overload the `add`, `query` and `update_context` methods to implement the desired functionality and pass the memory store to your agent.\n\nCurrently the following example memory stores are available as part of the `autogen_ext` extensions package.\n\n- `autogen_ext.memory.chromadb.ChromaDBVectorMemory`: A memory store that uses a vector database to store and retrieve information.\n- `autogen_ext.memory.chromadb.SentenceTransformerEmbeddingFunctionConfig`: A configuration class for the SentenceTransformer embedding function used by the ChromaDBVectorMemory store. Note that other embedding functions such as `autogen_ext.memory.openai.OpenAIEmbeddingFunctionConfig` can also be used with the ChromaDBVectorMemory store.\n\n```python\nimport tempfile\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core.memory import MemoryContent, MemoryMimeType\nfrom autogen_ext.memory.chromadb import (\n    ChromaDBVectorMemory,\n    PersistentChromaDBVectorMemoryConfig,\n    SentenceTransformerEmbeddingFunctionConfig,\n)\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n# Use a temporary directory for ChromaDB persistence\nwith tempfile.TemporaryDirectory() as tmpdir:\n    chroma_user_memory = ChromaDBVectorMemory(\n        config=PersistentChromaDBVectorMemoryConfig(\n            collection_name=\"preferences\",\n            persistence_path=tmpdir,  # Use the temp directory here\n            k=2,  # Return top k results\n            score_threshold=0.4,  # Minimum similarity score\n            embedding_function_config=SentenceTransformerEmbeddingFunctionConfig(\n                model_name=\"all-MiniLM-L6-v2\"  # Use default model for testing\n            ),\n        )\n    )\n    # Add user preferences to memory\n    await chroma_user_memory.add(\n        MemoryContent(\n            content=\"The weather should be in metric units\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"units\"},\n        )\n    )\n\n    await chroma_user_memory.add(\n        MemoryContent(\n            content=\"Meal recipe must be vegan\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n        )\n    )\n\n    model_client = OpenAIChatCompletionClient(\n        model=\"gpt-4o\",\n    )\n\n    # Create assistant agent with\n------------------------\noutput:\n(\"entity\"<|>ADD<|>TOOL<|>The `add` method is used to add content to the memory store, such as user preferences or other data)\n##\n(\"entity\"<|>QUERY<|>TOOL<|>The `query` method is used to retrieve information from the memory store based on specific criteria or similarity scores)\n##\n(\"entity\"<|>UPDATE_CONTEXT<|>TOOL<|>The `update_context` method is used to modify or update the context of the memory store to reflect new information or changes)\n##\n(\"entity\"<|>CHROMADBVECTORMEMORY<|>MEMORY_STORE<|>A memory store that uses a vector database to store and retrieve information, part of the `autogen_ext` extensions package)\n##\n(\"entity\"<|>SENTENCETRANSFORMEREMBEDDINGFUNCTIONCONFIG<|>CONFIGURATION<|>A configuration class for the SentenceTransformer embedding function used by the ChromaDBVectorMemory store, specifying the model and its parameters)\n##\n(\"entity\"<|>OPENAIEMBEDDINGFUNCTIONCONFIG<|>CONFIGURATION<|>An alternative embedding function configuration that can also be used with the ChromaDBVectorMemory store)\n##\n(\"entity\"<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>CONFIGURATION<|>A configuration class for persistent storage of ChromaDBVectorMemory, including parameters like collection name, persistence path, and similarity thresholds)\n##\n(\"entity\"<|>MEMORYCONTENT<|>COMPONENT<|>A component representing the content to be stored in memory, including attributes like content, MIME type, and metadata)\n##\n(\"entity\"<|>MEMORYMIMETYPE<|>COMPONENT<|>A component specifying the MIME type of the memory content, such as TEXT)\n##\n(\"entity\"<|>OPENAICHATCOMPLETIONCLIENT<|>MODEL_CLIENT<|>A model client for interacting with OpenAI's GPT-4 model, used for generating responses or performing tasks)\n##\n(\"entity\"<|>ASSISTANTAGENT<|>AGENT<|>An agent created to assist with tasks, leveraging memory stores and model clients for enhanced functionality)\n##\n(\"entity\"<|>TEMPFILE<|>COMPONENT<|>A component used to create temporary directories for storing persistent memory data during runtime)\n##\n(\"relationship\"<|>CHROMADBVECTORMEMORY<|>SENTENCETRANSFORMEREMBEDDINGFUNCTIONCONFIG<|>The ChromaDBVectorMemory store uses the SentenceTransformerEmbeddingFunctionConfig for embedding functions<|>8)\n##\n(\"relationship\"<|>CHROMADBVECTORMEMORY<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>The ChromaDBVectorMemory store is configured for persistence using PersistentChromaDBVectorMemoryConfig<|>9)\n##\n(\"relationship\"<|>CHROMADBVECTORMEMORY<|>MEMORYCONTENT<|>The ChromaDBVectorMemory store stores MemoryContent, which includes user preferences and other data<|>8)\n##\n(\"relationship\"<|>MEMORYCONTENT<|>MEMORYMIMETYPE<|>MemoryContent specifies its MIME type using MemoryMimeType, such as TEXT<|>7)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>CHROMADBVECTORMEMORY<|>The AssistantAgent uses the ChromaDBVectorMemory store to manage and retrieve memory<|>9)\n##\n(\"relationship\"<|>ASSISTANTAGENT<|>OPENAICHATCOMPLETIONCLIENT<|>The AssistantAgent uses the OpenAIChatCompletionClient for generating responses and performing tasks<|>9)\n##\n(\"relationship\"<|>TEMPFILE<|>PERSISTENTCHROMADBVECTORMEMORYCONFIG<|>Tempfile is used to create a temporary directory for the persistence path in PersistentChromaDBVectorMemoryConfig<|>6)\n##\n(\"relationship\"<|>ADD<|>CHROMADBVECTORMEMORY<|>The `add` method is used to add data to the ChromaDBVectorMemory store<|>8)\n##\n(\"relationship\"<|>QUERY<|>CHROMADBVECTORMEMORY<|>The `query` method is used to retrieve data from the ChromaDBVectorMemory store<|>8)\n##\n(\"relationship\"<|>UPDATE_CONTEXT<|>CHROMADBVECTORMEMORY<|>The `update_context` method is used to modify the context of the ChromaDBVectorMemory store<|>7)\n<|COMPLETE|>\n#############################\n\n\nExample 2:\n\nentity_types: [agent, memory_store, embedding_function, configuration, component, tool, message, event, termination_condition, subscription, task, model_client, reasoning_model, context, workflow]\ntext:\n on actions *within* the agent itself, and belong to subclasses of the base class `BaseAgentEvent`.\n\nExamples of these include `ToolCallRequestEvent`, which indicates that a request was made to call a tool, and `ToolCallExecutionEvent`, which contains the results of tool calls.\n\nTypically, events are created by the agent itself and are contained in the `inner_messages` field of the `Response` returned from `on_messages`. If you are building a custom agent and have events that you want to communicate to other entities (e.g., a UI), you can include these in the `inner_messages` field of the `Response`. We will show examples of this in Custom Agents.\n\nYou can read about the full set of messages supported in AgentChat in the `messages` module.\n\n## Custom Message Types\n\nYou can create custom message types by subclassing the base class `BaseChatMessage` or `BaseAgentEvent`. This allows you to define your own message formats and behaviors, tailored to your application. Custom message types are useful when you write custom agents.\n\n------------------------\noutput:\n(\"entity\"<|>BASEAGENTEVENT<|>event<|>Base class for events within the agent itself, used to define specific types of agent-related events)\n##\n(\"entity\"<|>TOOLCALLREQUESTEVENT<|>event<|>An event indicating that a request was made to call a tool)\n##\n(\"entity\"<|>TOOLCALLEXECUTIONEVENT<|>event<|>An event containing the results of tool calls)\n##\n(\"entity\"<|>INNER_MESSAGES<|>message<|>Field in the `Response` object that contains events created by the agent itself, such as tool call events)\n##\n(\"entity\"<|>RESPONSE<|>message<|>Object returned from `on_messages` that contains fields like `inner_messages` to communicate events)\n##\n(\"entity\"<|>BASECHATMESSAGE<|>message<|>Base class for creating custom message types tailored to specific applications)\n##\n(\"entity\"<|>AGENTCHAT<|>component<|>Module that supports a full set of messages for agent communication)\n##\n(\"entity\"<|>CUSTOM AGENTS<|>agent<|>Agents that are built with custom events and message types to communicate with other entities, such as UIs)\n##\n(\"relationship\"<|>TOOLCALLREQUESTEVENT<|>BASEAGENTEVENT<|>ToolCallRequestEvent is a subclass of BaseAgentEvent, representing a specific type of event<|>8)\n##\n(\"relationship\"<|>TOOLCALLEXECUTIONEVENT<|>BASEAGENTEVENT<|>ToolCallExecutionEvent is a subclass of BaseAgentEvent, representing a specific type of event<|>8)\n##\n(\"relationship\"<|>INNER_MESSAGES<|>RESPONSE<|>Inner_messages is a field in the Response object that contains events created by the agent<|>9)\n##\n(\"relationship\"<|>CUSTOM AGENTS<|>INNER_MESSAGES<|>Custom agents can include events in the inner_messages field to communicate with other entities<|>7)\n##\n(\"relationship\"<|>BASECHATMESSAGE<|>CUSTOM AGENTS<|>Custom agents can use BaseChatMessage to define their own message formats and behaviors<|>8)\n##\n(\"relationship\"<|>AGENTCHAT<|>RESPONSE<|>AgentChat supports the full set of messages, including those contained in the Response object<|>6)\n<|COMPLETE|>\n#############################\n\n\n\n-Real Data-\n######################\nentity_types: [agent, memory_store, embedding_function, configuration, component, tool, message, event, termination_condition, subscription, task, model_client, reasoning_model, context, workflow]\ntext: # Memory and RAG\n\nThere are several use cases where it is valuable to maintain a store of useful facts that can be intelligently added to the context of the agent just before a specific step. The typically use case here is a RAG pattern where a query is used to retrieve relevant information from a database that is then added to the agent's context.\n\nAgentChat provides a **Memory protocol** that can be extended to provide this functionality. The key methods are `query`, `update_context`, `add`, `clear`, and `close`.\n\n- **add**: add new entries to the memory store\n- **query**: retrieve relevant information from the memory store\n- **update_context**: mutate an agent's internal `model_context` by adding the retrieved information (used in the AssistantAgent class)\n- **clear**: clear all entries from the memory store\n- **close**: clean up any resources used by the memory store\n\n## ListMemory Example\n\n`ListMemory` is provided as an example implementation of the Memory protocol. It is a simple list-based memory implementation that maintains memories in chronological order, appending the most recent memories to the model's context. The implementation is designed to be straightforward and predictable, making it easy to understand and debug. In the following example, we will use `ListMemory` to maintain a memory bank of user preferences and demonstrate how it can be used to provide consistent context for agent responses over time.\n\n```python\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n# Initialize user memory\nuser_memory = ListMemory()\n\n# Add user preferences to memory\nawait user_memory.add(MemoryContent(content=\"The weather should be in metric units\", mime_type=MemoryMimeType.TEXT))\n\nawait user_memory.add(MemoryContent(content=\"Meal recipe must be vegan\", mime_type=MemoryMimeType.TEXT))\n\n\nasync def get_weather(city: str, units: str = \"imperial\") -> str:\n    if units == \"imperial\":\n        return f\"The weather in {city} is 73 °F and Sunny.\"\n    elif units == \"metric\":\n        return f\"The weather in {city} is 23 °C and Sunny.\"\n    else:\n        return f\"Sorry, I don't know the weather in {city}.\"\n\n\nassistant_agent = AssistantAgent(\n    name=\"assistant_agent\",\n    model_client=OpenAIChatCompletionClient(\n        model=\"gpt-4o-2024-08-06\",\n    ),\n    tools=[get_weather],\n    memory=[user_memory],\n)\n\n# Run the agent with a task.\nstream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\nawait Console(stream)\n```\n\nWe can inspect that the `assistant_agent` `model_context` is actually updated with the retrieved memory entries. The transform method is used to format the retrieved memory entries into a string that can be used by the agent. In this case, we simply concatenate the content of each memory entry into a single string.\n\n```python\nawait assistant_agent._model_context.get_messages()\n```\n\nWe see above that the weather is returned in Centigrade as stated in the user preferences.\n\nSimilarly, assuming we ask a separate question about generating a meal plan, the agent is able to retrieve relevant information from the memory store and provide a personalized (vegan) response.\n\n```python\nstream = assistant_agent.run_stream(task=\"Write brief meal recipe with broth\")\nawait Console(stream)\n```\n\n## Custom Memory Stores (Vector DBs, etc.)\n\nYou can build on the Memory protocol to implement more complex memory stores. For example, you could implement a custom memory store that uses a vector database to store and retrieve information, or a memory store that uses a machine learning model to generate personalized responses based on the user's preferences etc.\n\nSpecifically, you will need to overload the `add`, `query` and `update_context` methods to implement the desired functionality and pass the memory store to your agent.\n\nCurrently the following example memory stores are available as part of the `autogen_ext` extensions package.\n\n- `autogen_ext.memory.chromadb.ChromaDBVectorMemory`: A memory store that uses a vector database to store and retrieve information.\n- `autogen_ext.memory.chromadb.SentenceTransformerEmbeddingFunctionConfig`: A configuration class for the SentenceTransformer embedding function used by the ChromaDBVectorMemory store. Note that other embedding functions such as `autogen_ext.memory.openai.OpenAIEmbeddingFunctionConfig` can also be used with the ChromaDBVectorMemory store.\n\n```python\nimport tempfile\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core.memory import MemoryContent, MemoryMimeType\nfrom autogen_ext.memory.chromadb import (\n    ChromaDBVectorMemory,\n    PersistentChromaDBVectorMemoryConfig,\n    SentenceTransformerEmbeddingFunctionConfig,\n)\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n# Use a temporary directory for ChromaDB persistence\nwith tempfile.TemporaryDirectory() as tmpdir:\n    chroma_user_memory = ChromaDBVectorMemory(\n        config=PersistentChromaDBVectorMemoryConfig(\n            collection_name=\"preferences\",\n            persistence_path=tmpdir,  # Use the temp directory here\n            k=2,  # Return top k results\n            score_threshold=0.4,  # Minimum similarity score\n            embedding_function_config=SentenceTransformerEmbeddingFunctionConfig(\n                model_name=\"all-MiniLM-L6-v2\"  # Use default model for testing\n            ),\n        )\n    )\n    # Add user preferences to memory\n    await chroma_user_memory.add(\n        MemoryContent(\n            content=\"The weather should be in metric units\",\n######################\noutput:", "role": "user"}], "parameters": {"model": "gpt-4o", "frequency_penalty": 0.0, "max_tokens": null, "n": 1, "presence_penalty": 0.0, "temperature": 0.0, "top_p": 1.0}}, "key": "chat_2aa7fbb348aa8cc5e0bfc3ef14ab2372cff8d84182c1a2d8e0743ca7bb30bf7a_v2"}